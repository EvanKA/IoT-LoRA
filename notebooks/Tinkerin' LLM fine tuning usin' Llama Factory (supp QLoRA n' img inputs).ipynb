{"cells":[{"cell_type":"markdown","metadata":{"id":"1oHFCsV0z-Jw"},"source":["# Finetune Llama-3 with LLaMA Factory\n","\n","Please use a **free** Tesla T4 Colab GPU to run this!\n","\n","Project homepage: https://github.com/hiyouga/LLaMA-Factory"]},{"cell_type":"markdown","metadata":{"id":"lr7rB3szzhtx"},"source":["## Install Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261101,"status":"ok","timestamp":1726993863136,"user":{"displayName":"Evan Kurnia Alim","userId":"06904118571109037203"},"user_tz":-420},"id":"giM74oK1rRIH","outputId":"35135f96-36ff-4dc9-fe08-5eb864a085c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'LLaMA-Factory'...\n","remote: Enumerating objects: 315, done.\u001b[K\n","remote: Counting objects: 100% (315/315), done.\u001b[K\n","remote: Compressing objects: 100% (244/244), done.\u001b[K\n","remote: Total 315 (delta 80), reused 166 (delta 58), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (315/315), 8.94 MiB | 10.92 MiB/s, done.\n","Resolving deltas: 100% (80/80), done.\n","/content/LLaMA-Factory\n","\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mdocker\u001b[0m/      LICENSE      pyproject.toml  requirements.txt  \u001b[01;34msrc\u001b[0m/\n","CITATION.cff  \u001b[01;34mevaluation\u001b[0m/  Makefile     README.md       \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\n","\u001b[01;34mdata\u001b[0m/         \u001b[01;34mexamples\u001b[0m/    MANIFEST.in  README_zh.md    setup.py\n","Collecting torch==2.3.1\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.18.1\n","  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Collecting torchaudio==2.3.1\n","  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.1 (from torch==2.3.1)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (10.4.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1)\n","  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n","Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.1+cu121\n","    Uninstalling torch-2.4.1+cu121:\n","      Successfully uninstalled torch-2.4.1+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.19.1+cu121\n","    Uninstalling torchvision-0.19.1+cu121:\n","      Successfully uninstalled torchvision-0.19.1+cu121\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.4.1+cu121\n","    Uninstalling torchaudio-2.4.1+cu121:\n","      Successfully uninstalled torchaudio-2.4.1+cu121\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.3.1 torchaudio-2.3.1 torchvision-0.18.1 triton-2.3.1\n","Collecting auto_gptq\n","  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.34.2)\n","Collecting datasets (from auto_gptq)\n","  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.1.99)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (1.26.4)\n","Collecting rouge (from auto_gptq)\n","  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n","Collecting gekko (from auto_gptq)\n","  Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (2.3.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.4.5)\n","Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (4.44.2)\n","Collecting peft>=0.5.0 (from auto_gptq)\n","  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (4.66.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (6.0.2)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (0.24.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto_gptq) (12.6.68)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (0.19.1)\n","Collecting pyarrow>=15.0.0 (from datasets->auto_gptq)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->auto_gptq)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (2.1.4)\n","Collecting xxhash (from datasets->auto_gptq)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets->auto_gptq)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (3.10.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto_gptq) (1.16.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto_gptq) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2024.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto_gptq) (1.3.0)\n","Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, rouge, pyarrow, gekko, dill, multiprocess, peft, datasets, auto_gptq\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed auto_gptq-0.7.1 datasets-3.0.0 dill-0.3.8 gekko-1.2.1 multiprocess-0.70.16 peft-0.12.0 pyarrow-17.0.0 rouge-1.0.1 xxhash-3.5.0\n","Collecting optimum\n","  Downloading optimum-1.22.0-py3-none-any.whl.metadata (20 kB)\n","Collecting coloredlogs (from optimum)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.2)\n","Requirement already satisfied: transformers<4.45.0,>=4.29 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (4.44.2)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum) (24.1)\n","Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (1.26.4)\n","Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (0.24.7)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2024.6.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum) (12.6.68)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.19.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (3.20.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum) (0.1.99)\n","Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (2.1.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.16)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.10.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n","Downloading optimum-1.22.0-py3-none-any.whl (453 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.7/453.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, optimum\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.22.0\n","Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-fypxkl0m\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-fypxkl0m\n","  Resolved https://github.com/huggingface/transformers.git to commit 78b2929c0554b79e0489b451ce4ece14d265ead2\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2024.8.30)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9786808 sha256=108f1d5c07d0439afbe8859b32f1a85357c399fae2568ca325c449a90edb8540\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-g6o8cqs0/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n","Successfully built transformers\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.2\n","    Uninstalling transformers-4.44.2:\n","      Successfully uninstalled transformers-4.44.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","optimum 1.22.0 requires transformers[sentencepiece]<4.45.0,>=4.29, but you have transformers 4.45.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed transformers-4.45.0.dev0\n","Found existing installation: jax 0.4.26\n","Uninstalling jax-0.4.26:\n","  Successfully uninstalled jax-0.4.26\n","Obtaining file:///content/LLaMA-Factory\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (4.45.0.dev0)\n","Collecting datasets<=2.21.0,>=2.16.0 (from llamafactory==0.9.1.dev0)\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: accelerate<=0.34.2,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.34.2)\n","Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.12.0)\n","Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.1.dev0)\n","  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n","Collecting gradio>=4.0.0 (from llamafactory==0.9.1.dev0)\n","  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.1.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.13.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.8.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.1.99)\n","Collecting tiktoken (from llamafactory==0.9.1.dev0)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.20.3)\n","Collecting uvicorn (from llamafactory==0.9.1.dev0)\n","  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.9.2)\n","Collecting fastapi (from llamafactory==0.9.1.dev0)\n","  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n","Collecting sse-starlette (from llamafactory==0.9.1.dev0)\n","  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.7.1)\n","Collecting fire (from llamafactory==0.9.1.dev0)\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (24.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (6.0.2)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.26.4)\n","Collecting liger-kernel (from llamafactory==0.9.1.dev0)\n","  Downloading liger_kernel-0.3.0-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.3.1)\n","Collecting bitsandbytes>=0.39.0 (from llamafactory==0.9.1.dev0)\n","  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (5.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.24.7)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.3.8)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.10.5)\n","Collecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.7.1)\n","Collecting ffmpy (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.3.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting httpx>=0.24.1 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (6.4.5)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.1.5)\n","Collecting orjson~=3.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (10.4.0)\n","Collecting pydub (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.9 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading python_multipart-0.0.10-py3-none-any.whl.metadata (1.9 kB)\n","Collecting ruff>=0.2.2 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting semantic-version~=2.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tomlkit==0.12.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.12.5)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (4.12.2)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.0.7)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting starlette<0.39.0,>=0.37.2 (from fastapi->llamafactory==0.9.1.dev0)\n","  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (2.23.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (3.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.9.1.dev0) (12.6.68)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (0.19.1)\n","Collecting tyro>=0.5.11 (from trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0)\n","  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn->llamafactory==0.9.1.dev0)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (2.4.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.2.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.0.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2024.8.30)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.3.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (13.8.1)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.16)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->llamafactory==0.9.1.dev0) (1.3.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.1.2)\n","Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading liger_kernel-0.3.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.10-py3-none-any.whl (22 kB)\n","Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.38.5-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: llamafactory, fire\n","  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llamafactory: filename=llamafactory-0.9.1.dev0-0.editable-py3-none-any.whl size=22392 sha256=af46851169f27c07aed80bd6da3795b0bde77197400774498b83c974fc6454f1\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-1pstf3te/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=cde335f8c79ca32ee0e4bb62239a510b309e6310c78710ade7e102435b589eb2\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","Successfully built llamafactory fire\n","Installing collected packages: pydub, websockets, tomlkit, shtab, semantic-version, ruff, python-multipart, orjson, h11, fire, ffmpy, aiofiles, uvicorn, tiktoken, starlette, httpcore, tyro, sse-starlette, httpx, fastapi, gradio-client, bitsandbytes, liger-kernel, gradio, datasets, trl, llamafactory\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 3.0.0\n","    Uninstalling datasets-3.0.0:\n","      Successfully uninstalled datasets-3.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","optimum 1.22.0 requires transformers[sentencepiece]<4.45.0,>=4.29, but you have transformers 4.45.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 bitsandbytes-0.43.3 datasets-2.21.0 fastapi-0.115.0 ffmpy-0.4.0 fire-0.6.0 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 liger-kernel-0.3.0 llamafactory-0.9.1.dev0 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.10 ruff-0.6.7 semantic-version-2.10.0 shtab-1.7.1 sse-starlette-2.1.3 starlette-0.38.5 tiktoken-0.7.0 tomlkit-0.12.0 trl-0.9.6 tyro-0.8.11 uvicorn-0.30.6 websockets-12.0\n"]}],"source":["%cd /content/\n","%rm -rf LLaMA-Factory\n","!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n","%cd LLaMA-Factory\n","%ls\n","!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n","!pip install auto_gptq\n","!pip install optimum\n","!pip install git+https://github.com/huggingface/transformers.git\n","!pip uninstall -y jax\n","!pip install -e .[torch,bitsandbytes,liger-kernel]"]},{"cell_type":"markdown","metadata":{"id":"H9RXn_YQnn9f"},"source":["### Check GPU environment"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3405,"status":"ok","timestamp":1726993866529,"user":{"displayName":"Evan Kurnia Alim","userId":"06904118571109037203"},"user_tz":-420},"id":"ZkN-ktlsnrdU"},"outputs":[],"source":["import torch\n","try:\n","  assert torch.cuda.is_available() is True\n","except AssertionError:\n","  print(\"Please set up a GPU before using LLaMA Factory: https://medium.com/mlearning-ai/training-yolov4-on-google-colab-316f8fff99c6\")"]},{"cell_type":"markdown","metadata":{"id":"TeYs5Lz-QJYk"},"source":["## Update Identity Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1726993866530,"user":{"displayName":"Evan Kurnia Alim","userId":"06904118571109037203"},"user_tz":-420},"id":"ap_fvMBsQHJc","outputId":"fedafa3b-468f-4249-9431-abb18d5739a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n"]}],"source":["import json\n","\n","%cd /content/LLaMA-Factory/\n","\n","NAME = \"Llava\"\n","AUTHOR = \"Pujianto Yugopuspito et al.\"\n","\n","with open(\"data/identity.json\", \"r\", encoding=\"utf-8\") as f:\n","  dataset = json.load(f)\n","\n","for sample in dataset:\n","  sample[\"output\"] = sample[\"output\"].replace(\"{{\"+ \"name\" + \"}}\", NAME).replace(\"{{\"+ \"author\" + \"}}\", AUTHOR)\n","\n","with open(\"data/identity.json\", \"w\", encoding=\"utf-8\") as f:\n","  json.dump(dataset, f, indent=2, ensure_ascii=False)"]},{"cell_type":"markdown","metadata":{"id":"2QiXcvdzzW3Y"},"source":["## Fine-tune model via LLaMA Board"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLsdS6V5yUMy","outputId":"f31141ac-ee46-48c7-c619-59b7fa9a1396"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n","2024-09-22 08:31:16.452258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-22 08:31:16.731743: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-22 08:31:16.810966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-22 08:31:17.256674: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-22 08:31:19.493863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Running on local URL:  http://0.0.0.0:7860\n","Running on public URL: https://53cca447bbdd2915e6.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","2024-09-22 08:32:52.954515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-22 08:32:52.974479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-22 08:32:52.980751: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-22 08:32:52.995941: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-22 08:32:54.177573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","09/22/2024 08:33:00 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n","09/22/2024 08:33:00 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n","config.json: 100% 1.10k/1.10k [00:00<00:00, 7.89MB/s]\n","[INFO|configuration_utils.py:672] 2024-09-22 08:33:01,276 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/config.json\n","[INFO|configuration_utils.py:739] 2024-09-22 08:33:01,281 >> Model config LlavaConfig {\n","  \"_name_or_path\": \"llava-hf/llava-1.5-13b-hf\",\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_seq_length\": 576,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"meta-llama/Llama-2-13b-hf\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"attention_bias\": false,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": 1,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 2,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"head_dim\": 128,\n","    \"hidden_act\": \"silu\",\n","    \"hidden_size\": 5120,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 13824,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 4096,\n","    \"min_length\": 0,\n","    \"mlp_bias\": false,\n","    \"model_type\": \"llama\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 40,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 40,\n","    \"num_key_value_heads\": 40,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"prefix\": null,\n","    \"pretraining_tp\": 1,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"rms_norm_eps\": 1e-05,\n","    \"rope_scaling\": null,\n","    \"rope_theta\": 10000.0,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": false,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": \"float16\",\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.45.0.dev0\",\n","  \"vision_config\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": null,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"quick_gelu\",\n","    \"hidden_size\": 1024,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"image_size\": 336,\n","    \"initializer_factor\": 1.0,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 4096,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-05,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"min_length\": 0,\n","    \"model_type\": \"clip_vision_model\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 16,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 24,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"patch_size\": 14,\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"projection_dim\": 768,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\",\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer_config.json: 100% 1.36k/1.36k [00:00<00:00, 9.47MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 19.8MB/s]\n","tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 2.29MB/s]\n","added_tokens.json: 100% 41.0/41.0 [00:00<00:00, 231kB/s]\n","special_tokens_map.json: 100% 552/552 [00:00<00:00, 4.03MB/s]\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:04,438 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.model\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:04,438 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:04,438 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/added_tokens.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:04,438 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:04,438 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2479] 2024-09-22 08:33:04,523 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","preprocessor_config.json: 100% 505/505 [00:00<00:00, 3.34MB/s]\n","[INFO|image_processing_base.py:375] 2024-09-22 08:33:05,415 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/preprocessor_config.json\n","[INFO|image_processing_base.py:375] 2024-09-22 08:33:05,639 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/preprocessor_config.json\n","[INFO|image_processing_base.py:429] 2024-09-22 08:33:05,641 >> Image processor CLIPImageProcessor {\n","  \"crop_size\": {\n","    \"height\": 336,\n","    \"width\": 336\n","  },\n","  \"do_center_crop\": true,\n","  \"do_convert_rgb\": true,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.48145466,\n","    0.4578275,\n","    0.40821073\n","  ],\n","  \"image_processor_type\": \"CLIPImageProcessor\",\n","  \"image_std\": [\n","    0.26862954,\n","    0.26130258,\n","    0.27577711\n","  ],\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 336\n","  }\n","}\n","\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:05,871 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.model\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:05,872 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:05,872 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/added_tokens.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:05,872 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 08:33:05,872 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2479] 2024-09-22 08:33:05,930 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","chat_template.json: 100% 700/700 [00:00<00:00, 4.94MB/s]\n","[INFO|processing_utils.py:744] 2024-09-22 08:33:06,710 >> Processor LlavaProcessor:\n","- image_processor: CLIPImageProcessor {\n","  \"crop_size\": {\n","    \"height\": 336,\n","    \"width\": 336\n","  },\n","  \"do_center_crop\": true,\n","  \"do_convert_rgb\": true,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.48145466,\n","    0.4578275,\n","    0.40821073\n","  ],\n","  \"image_processor_type\": \"CLIPImageProcessor\",\n","  \"image_std\": [\n","    0.26862954,\n","    0.26130258,\n","    0.27577711\n","  ],\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 336\n","  }\n","}\n","\n","- tokenizer: LlamaTokenizerFast(name_or_path='llava-hf/llava-1.5-13b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n","\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32000: AddedToken(\"<image>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32001: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n","\n","{\n","  \"image_token\": \"<image>\",\n","  \"patch_size\": null,\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"vision_feature_select_strategy\": null\n","}\n","\n","09/22/2024 08:33:06 - INFO - llamafactory.data.loader - Loading dataset llamafactory/alpaca_en...\n","Downloading readme: 100% 506/506 [00:00<00:00, 2.21kB/s]\n","Downloading data: 100% 22.7M/22.7M [00:01<00:00, 15.1MB/s]\n","Generating train split: 51699 examples [00:00, 62162.98 examples/s]\n","Converting format of dataset (num_proc=16): 100% 500/500 [00:00<00:00, 854.12 examples/s]\n","Running tokenizer on dataset (num_proc=16): 100% 500/500 [00:02<00:00, 217.36 examples/s]\n","training example:\n","input_ids:\n","[319, 13563, 1546, 263, 12758, 1404, 322, 385, 23116, 21082, 20255, 29889, 450, 20255, 4076, 8444, 29892, 13173, 29892, 322, 1248, 568, 6089, 304, 278, 1404, 29915, 29879, 5155, 29889, 3148, 1001, 29901, 25538, 2211, 25562, 363, 7952, 292, 9045, 29891, 29889, 319, 1799, 9047, 13566, 29901, 29871, 29896, 29889, 382, 271, 263, 6411, 8362, 652, 300, 322, 1207, 1854, 304, 3160, 20947, 310, 285, 21211, 322, 18655, 1849, 29889, 29871, 13, 29906, 29889, 1222, 6269, 895, 25704, 304, 3013, 596, 3573, 6136, 322, 4549, 29889, 29871, 13, 29941, 29889, 3617, 3307, 8709, 322, 7344, 263, 13747, 8709, 20410, 29889, 2]\n","inputs:\n","A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Give three tips for staying healthy. ASSISTANT: 1. Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n","2. Exercise regularly to keep your body active and strong. \n","3. Get enough sleep and maintain a consistent sleep schedule.</s>\n","label_ids:\n","[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 29896, 29889, 382, 271, 263, 6411, 8362, 652, 300, 322, 1207, 1854, 304, 3160, 20947, 310, 285, 21211, 322, 18655, 1849, 29889, 29871, 13, 29906, 29889, 1222, 6269, 895, 25704, 304, 3013, 596, 3573, 6136, 322, 4549, 29889, 29871, 13, 29941, 29889, 3617, 3307, 8709, 322, 7344, 263, 13747, 8709, 20410, 29889, 2]\n","labels:\n","1. Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n","2. Exercise regularly to keep your body active and strong. \n","3. Get enough sleep and maintain a consistent sleep schedule.</s>\n","[INFO|configuration_utils.py:672] 2024-09-22 08:33:16,965 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/config.json\n","[INFO|configuration_utils.py:739] 2024-09-22 08:33:16,967 >> Model config LlavaConfig {\n","  \"_name_or_path\": \"llava-hf/llava-1.5-13b-hf\",\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_seq_length\": 576,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"meta-llama/Llama-2-13b-hf\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"attention_bias\": false,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": 1,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 2,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"head_dim\": 128,\n","    \"hidden_act\": \"silu\",\n","    \"hidden_size\": 5120,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 13824,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 4096,\n","    \"min_length\": 0,\n","    \"mlp_bias\": false,\n","    \"model_type\": \"llama\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 40,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 40,\n","    \"num_key_value_heads\": 40,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"prefix\": null,\n","    \"pretraining_tp\": 1,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"rms_norm_eps\": 1e-05,\n","    \"rope_scaling\": null,\n","    \"rope_theta\": 10000.0,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": false,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": \"float16\",\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.45.0.dev0\",\n","  \"vision_config\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": null,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"quick_gelu\",\n","    \"hidden_size\": 1024,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"image_size\": 336,\n","    \"initializer_factor\": 1.0,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 4096,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-05,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"min_length\": 0,\n","    \"model_type\": \"clip_vision_model\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 16,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 24,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"patch_size\": 14,\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"projection_dim\": 768,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\",\n","  \"vocab_size\": 32064\n","}\n","\n","09/22/2024 08:33:16 - INFO - llamafactory.model.model_utils.quantization - Quantizing model to 4 bit with bitsandbytes.\n","model.safetensors.index.json: 100% 77.2k/77.2k [00:00<00:00, 379kB/s]\n","[INFO|modeling_utils.py:3702] 2024-09-22 08:33:18,104 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/model.safetensors.index.json\n","Downloading shards:   0% 0/6 [00:00<?, ?it/s]\n","model-00001-of-00006.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n","model-00001-of-00006.safetensors:   0% 10.5M/4.96G [00:00<01:08, 72.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   0% 21.0M/4.96G [00:00<01:08, 72.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   1% 31.5M/4.96G [00:00<01:09, 71.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   1% 41.9M/4.96G [00:00<01:10, 69.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   1% 52.4M/4.96G [00:00<01:07, 72.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   1% 62.9M/4.96G [00:00<01:08, 72.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   1% 73.4M/4.96G [00:01<01:12, 67.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   2% 83.9M/4.96G [00:01<01:17, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   2% 94.4M/4.96G [00:01<01:16, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   2% 105M/4.96G [00:01<01:14, 64.9MB/s] \u001b[A\n","model-00001-of-00006.safetensors:   2% 115M/4.96G [00:01<01:17, 62.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   3% 126M/4.96G [00:01<01:17, 62.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   3% 136M/4.96G [00:02<01:16, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   3% 147M/4.96G [00:02<01:14, 64.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   3% 157M/4.96G [00:02<01:13, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   3% 168M/4.96G [00:02<01:20, 59.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   4% 178M/4.96G [00:02<01:18, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   4% 189M/4.96G [00:02<01:24, 56.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   4% 199M/4.96G [00:03<01:20, 59.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   4% 210M/4.96G [00:03<01:14, 63.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   4% 220M/4.96G [00:03<01:10, 67.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   5% 231M/4.96G [00:03<01:08, 68.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   5% 241M/4.96G [00:03<01:05, 71.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   5% 252M/4.96G [00:03<01:04, 73.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   5% 262M/4.96G [00:03<01:05, 71.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   5% 273M/4.96G [00:04<01:04, 72.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   6% 283M/4.96G [00:04<01:05, 71.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   6% 294M/4.96G [00:04<01:05, 71.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   6% 304M/4.96G [00:04<01:15, 61.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   6% 315M/4.96G [00:04<01:16, 61.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   7% 325M/4.96G [00:04<01:17, 59.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   7% 336M/4.96G [00:05<01:13, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   7% 346M/4.96G [00:05<01:10, 65.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   7% 357M/4.96G [00:05<01:10, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   7% 367M/4.96G [00:05<01:15, 60.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   8% 377M/4.96G [00:05<01:11, 64.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   8% 388M/4.96G [00:05<01:10, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   8% 398M/4.96G [00:06<01:13, 62.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   8% 409M/4.96G [00:06<01:14, 60.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   8% 419M/4.96G [00:06<01:12, 62.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   9% 430M/4.96G [00:06<01:09, 65.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   9% 440M/4.96G [00:06<01:06, 67.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   9% 451M/4.96G [00:06<01:06, 67.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:   9% 461M/4.96G [00:07<01:07, 66.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  10% 472M/4.96G [00:07<01:06, 67.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  10% 482M/4.96G [00:07<01:11, 62.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  10% 493M/4.96G [00:07<01:10, 63.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  10% 503M/4.96G [00:07<01:08, 65.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  10% 514M/4.96G [00:07<01:10, 63.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  11% 524M/4.96G [00:08<01:09, 63.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  11% 535M/4.96G [00:08<01:14, 59.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  11% 545M/4.96G [00:08<01:13, 60.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  11% 556M/4.96G [00:08<01:12, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  11% 566M/4.96G [00:08<01:10, 62.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  12% 577M/4.96G [00:08<01:08, 63.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  12% 587M/4.96G [00:09<01:08, 63.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  12% 598M/4.96G [00:09<01:10, 61.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  12% 608M/4.96G [00:09<01:13, 59.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  12% 619M/4.96G [00:09<01:10, 61.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  13% 629M/4.96G [00:09<01:09, 62.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  13% 640M/4.96G [00:09<01:10, 61.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  13% 650M/4.96G [00:10<01:09, 62.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  13% 661M/4.96G [00:10<01:08, 62.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  14% 671M/4.96G [00:10<01:07, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  14% 682M/4.96G [00:10<01:04, 66.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  14% 692M/4.96G [00:10<01:03, 66.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  14% 703M/4.96G [00:10<01:05, 65.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  14% 713M/4.96G [00:11<01:02, 68.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  15% 724M/4.96G [00:11<01:02, 68.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  15% 734M/4.96G [00:11<01:01, 69.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  15% 744M/4.96G [00:11<01:06, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  15% 755M/4.96G [00:11<01:06, 63.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  15% 765M/4.96G [00:11<01:03, 65.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  16% 776M/4.96G [00:12<01:02, 66.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  16% 786M/4.96G [00:12<01:03, 65.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  16% 797M/4.96G [00:12<01:01, 68.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  16% 807M/4.96G [00:12<01:04, 64.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  16% 818M/4.96G [00:12<01:01, 67.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  17% 828M/4.96G [00:12<00:59, 69.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  17% 839M/4.96G [00:12<01:07, 61.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  17% 849M/4.96G [00:13<01:05, 63.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  17% 860M/4.96G [00:13<01:04, 64.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  18% 870M/4.96G [00:13<01:01, 66.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  18% 881M/4.96G [00:13<01:04, 63.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  18% 891M/4.96G [00:13<01:05, 61.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  18% 902M/4.96G [00:13<01:07, 60.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  18% 912M/4.96G [00:14<01:02, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  19% 923M/4.96G [00:14<01:05, 62.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  19% 933M/4.96G [00:14<01:04, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  19% 944M/4.96G [00:14<01:03, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  19% 954M/4.96G [00:14<01:04, 62.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  19% 965M/4.96G [00:14<01:02, 63.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  20% 975M/4.96G [00:15<01:01, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  20% 986M/4.96G [00:15<01:19, 50.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  20% 1.01G/4.96G [00:15<01:03, 62.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  20% 1.02G/4.96G [00:15<01:02, 62.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  21% 1.03G/4.96G [00:15<01:00, 64.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  21% 1.04G/4.96G [00:16<00:57, 67.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  21% 1.05G/4.96G [00:16<00:56, 69.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  21% 1.06G/4.96G [00:16<00:56, 69.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  22% 1.07G/4.96G [00:16<00:59, 65.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  22% 1.08G/4.96G [00:16<00:57, 67.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  22% 1.09G/4.96G [00:16<00:57, 67.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  22% 1.10G/4.96G [00:17<00:58, 66.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  22% 1.11G/4.96G [00:17<01:02, 61.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  23% 1.12G/4.96G [00:17<01:03, 60.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  23% 1.13G/4.96G [00:17<01:00, 63.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  23% 1.14G/4.96G [00:17<00:58, 65.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  23% 1.15G/4.96G [00:17<00:59, 63.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  23% 1.16G/4.96G [00:18<00:57, 65.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  24% 1.17G/4.96G [00:18<01:00, 62.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  24% 1.18G/4.96G [00:18<00:58, 65.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  24% 1.20G/4.96G [00:18<00:56, 67.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  24% 1.21G/4.96G [00:18<00:55, 68.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  25% 1.22G/4.96G [00:18<00:57, 65.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  25% 1.23G/4.96G [00:19<00:57, 64.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  25% 1.24G/4.96G [00:19<00:56, 66.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  25% 1.25G/4.96G [00:19<00:57, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  25% 1.26G/4.96G [00:19<01:02, 59.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  26% 1.27G/4.96G [00:19<00:59, 61.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  26% 1.28G/4.96G [00:19<00:57, 64.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  26% 1.29G/4.96G [00:20<00:56, 65.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  26% 1.30G/4.96G [00:20<00:54, 67.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  26% 1.31G/4.96G [00:20<00:54, 67.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  27% 1.32G/4.96G [00:20<00:51, 70.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  27% 1.33G/4.96G [00:20<00:52, 68.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  27% 1.34G/4.96G [00:20<00:51, 70.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  27% 1.35G/4.96G [00:20<00:53, 67.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  27% 1.36G/4.96G [00:21<00:55, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  28% 1.37G/4.96G [00:21<00:54, 66.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  28% 1.38G/4.96G [00:21<00:53, 66.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  28% 1.39G/4.96G [00:21<00:54, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  28% 1.41G/4.96G [00:21<00:55, 64.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  29% 1.42G/4.96G [00:21<00:57, 61.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  29% 1.43G/4.96G [00:22<00:56, 62.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  29% 1.44G/4.96G [00:22<00:55, 63.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  29% 1.45G/4.96G [00:22<01:03, 55.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  29% 1.46G/4.96G [00:22<01:00, 57.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  30% 1.47G/4.96G [00:22<00:57, 60.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  30% 1.48G/4.96G [00:22<00:54, 63.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  30% 1.49G/4.96G [00:23<01:04, 54.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  30% 1.51G/4.96G [00:23<00:49, 69.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  31% 1.52G/4.96G [00:23<00:52, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  31% 1.53G/4.96G [00:23<00:51, 66.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  31% 1.54G/4.96G [00:23<00:52, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  31% 1.55G/4.96G [00:24<00:51, 66.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  31% 1.56G/4.96G [00:24<00:52, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  32% 1.57G/4.96G [00:24<00:50, 66.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  32% 1.58G/4.96G [00:24<00:48, 69.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  32% 1.59G/4.96G [00:24<00:48, 69.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  32% 1.60G/4.96G [00:24<00:49, 67.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  33% 1.61G/4.96G [00:24<00:48, 69.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  33% 1.63G/4.96G [00:25<00:49, 67.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  33% 1.64G/4.96G [00:25<00:47, 70.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  33% 1.65G/4.96G [00:25<00:46, 72.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  33% 1.66G/4.96G [00:25<00:45, 72.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  34% 1.67G/4.96G [00:25<00:50, 65.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  34% 1.68G/4.96G [00:25<00:48, 68.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  34% 1.69G/4.96G [00:26<00:50, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  34% 1.70G/4.96G [00:26<00:58, 55.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  34% 1.71G/4.96G [00:26<00:56, 57.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  35% 1.72G/4.96G [00:26<00:57, 56.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  35% 1.73G/4.96G [00:26<00:53, 60.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  35% 1.74G/4.96G [00:26<00:50, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  35% 1.75G/4.96G [00:27<00:53, 60.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  36% 1.76G/4.96G [00:27<00:52, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  36% 1.77G/4.96G [00:27<00:51, 61.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  36% 1.78G/4.96G [00:27<00:49, 64.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  36% 1.79G/4.96G [00:27<00:46, 67.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  36% 1.80G/4.96G [00:27<00:46, 68.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  37% 1.81G/4.96G [00:28<00:44, 70.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  37% 1.82G/4.96G [00:28<00:43, 72.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  37% 1.84G/4.96G [00:28<00:44, 70.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  37% 1.85G/4.96G [00:28<00:42, 73.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  37% 1.86G/4.96G [00:28<00:41, 74.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  38% 1.87G/4.96G [00:28<00:42, 73.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  38% 1.88G/4.96G [00:28<00:42, 72.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  38% 1.89G/4.96G [00:29<00:41, 74.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  38% 1.90G/4.96G [00:29<00:41, 74.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  38% 1.91G/4.96G [00:29<00:42, 71.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  39% 1.92G/4.96G [00:29<00:44, 68.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  39% 1.93G/4.96G [00:29<00:43, 70.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  39% 1.94G/4.96G [00:29<00:41, 72.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  39% 1.95G/4.96G [00:29<00:41, 72.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  40% 1.96G/4.96G [00:30<00:42, 70.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  40% 1.97G/4.96G [00:30<00:41, 72.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  40% 1.98G/4.96G [00:30<00:41, 71.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  40% 1.99G/4.96G [00:30<00:49, 60.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  40% 2.00G/4.96G [00:30<00:46, 63.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  41% 2.01G/4.96G [00:30<00:45, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  41% 2.02G/4.96G [00:31<00:43, 66.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  41% 2.03G/4.96G [00:31<00:48, 60.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  41% 2.04G/4.96G [00:31<00:48, 60.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  41% 2.06G/4.96G [00:31<00:49, 59.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  42% 2.07G/4.96G [00:31<00:45, 63.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  42% 2.08G/4.96G [00:31<00:43, 65.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  42% 2.09G/4.96G [00:32<00:43, 65.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  42% 2.10G/4.96G [00:32<00:42, 67.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  42% 2.11G/4.96G [00:32<00:44, 64.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  43% 2.12G/4.96G [00:32<00:44, 64.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  43% 2.13G/4.96G [00:32<00:43, 65.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  43% 2.14G/4.96G [00:32<00:43, 65.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  43% 2.15G/4.96G [00:33<00:42, 66.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  44% 2.16G/4.96G [00:33<00:42, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  44% 2.17G/4.96G [00:33<00:42, 65.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  44% 2.18G/4.96G [00:33<00:47, 58.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  44% 2.19G/4.96G [00:33<00:53, 52.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  44% 2.20G/4.96G [00:34<00:48, 56.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  45% 2.21G/4.96G [00:34<00:46, 59.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  45% 2.22G/4.96G [00:34<00:43, 62.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  45% 2.23G/4.96G [00:34<00:41, 65.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  45% 2.24G/4.96G [00:34<00:42, 64.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  45% 2.25G/4.96G [00:34<00:42, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  46% 2.26G/4.96G [00:34<00:43, 62.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  46% 2.28G/4.96G [00:35<00:42, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  46% 2.29G/4.96G [00:35<00:42, 63.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  46% 2.30G/4.96G [00:35<00:42, 63.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  46% 2.31G/4.96G [00:35<00:43, 61.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  47% 2.32G/4.96G [00:35<00:43, 60.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  47% 2.33G/4.96G [00:35<00:41, 63.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  47% 2.34G/4.96G [00:36<00:42, 61.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  47% 2.35G/4.96G [00:36<00:43, 60.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  48% 2.36G/4.96G [00:36<00:42, 61.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  48% 2.37G/4.96G [00:36<00:40, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  48% 2.38G/4.96G [00:36<00:40, 63.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  48% 2.39G/4.96G [00:36<00:40, 63.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  48% 2.40G/4.96G [00:37<00:37, 67.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  49% 2.41G/4.96G [00:37<00:36, 69.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  49% 2.42G/4.96G [00:37<00:38, 65.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  49% 2.43G/4.96G [00:37<00:37, 68.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  49% 2.44G/4.96G [00:37<00:38, 65.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  49% 2.45G/4.96G [00:38<00:46, 54.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  50% 2.47G/4.96G [00:38<00:38, 64.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  50% 2.49G/4.96G [00:38<00:40, 60.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  50% 2.50G/4.96G [00:38<00:39, 62.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  51% 2.51G/4.96G [00:38<00:39, 62.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  51% 2.52G/4.96G [00:38<00:38, 63.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  51% 2.53G/4.96G [00:39<00:36, 66.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  51% 2.54G/4.96G [00:39<00:37, 64.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  51% 2.55G/4.96G [00:39<00:39, 61.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  52% 2.56G/4.96G [00:39<00:37, 64.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  52% 2.57G/4.96G [00:39<00:36, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  52% 2.58G/4.96G [00:39<00:37, 64.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  52% 2.59G/4.96G [00:40<00:38, 61.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  52% 2.60G/4.96G [00:40<00:38, 61.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  53% 2.61G/4.96G [00:40<00:37, 62.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  53% 2.62G/4.96G [00:40<00:40, 58.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  53% 2.63G/4.96G [00:40<00:39, 59.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  53% 2.64G/4.96G [00:40<00:38, 60.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  53% 2.65G/4.96G [00:41<00:37, 62.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  54% 2.66G/4.96G [00:41<00:39, 58.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  54% 2.67G/4.96G [00:41<00:37, 61.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  54% 2.68G/4.96G [00:41<00:36, 62.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  54% 2.69G/4.96G [00:41<00:38, 59.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  55% 2.71G/4.96G [00:42<00:36, 61.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  55% 2.72G/4.96G [00:42<00:35, 63.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  55% 2.73G/4.96G [00:42<00:33, 66.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  55% 2.74G/4.96G [00:42<00:32, 68.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  55% 2.75G/4.96G [00:42<00:31, 69.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  56% 2.76G/4.96G [00:42<00:31, 70.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  56% 2.77G/4.96G [00:42<00:31, 69.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  56% 2.78G/4.96G [00:43<00:33, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  56% 2.79G/4.96G [00:43<00:32, 67.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  56% 2.80G/4.96G [00:43<00:32, 67.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  57% 2.81G/4.96G [00:43<00:32, 65.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  57% 2.82G/4.96G [00:43<00:32, 66.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  57% 2.83G/4.96G [00:43<00:32, 64.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  57% 2.84G/4.96G [00:44<00:32, 66.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  57% 2.85G/4.96G [00:44<00:32, 64.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  58% 2.86G/4.96G [00:44<00:31, 67.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  58% 2.87G/4.96G [00:44<00:31, 67.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  58% 2.88G/4.96G [00:44<00:31, 66.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  58% 2.89G/4.96G [00:44<00:31, 65.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  59% 2.90G/4.96G [00:45<00:33, 62.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  59% 2.92G/4.96G [00:45<00:33, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  59% 2.93G/4.96G [00:45<00:32, 61.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  59% 2.94G/4.96G [00:45<00:32, 62.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  59% 2.95G/4.96G [00:45<00:32, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  60% 2.96G/4.96G [00:45<00:31, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  60% 2.97G/4.96G [00:45<00:30, 65.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  60% 2.98G/4.96G [00:46<00:31, 63.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  60% 2.99G/4.96G [00:46<00:31, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  60% 3.00G/4.96G [00:46<00:35, 55.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  61% 3.01G/4.96G [00:46<00:33, 58.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  61% 3.02G/4.96G [00:46<00:31, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  61% 3.03G/4.96G [00:47<00:30, 62.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  61% 3.04G/4.96G [00:47<00:30, 63.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  61% 3.05G/4.96G [00:47<00:28, 66.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  62% 3.06G/4.96G [00:47<00:27, 69.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  62% 3.07G/4.96G [00:47<00:26, 70.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  62% 3.08G/4.96G [00:47<00:25, 72.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  62% 3.09G/4.96G [00:47<00:25, 73.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  63% 3.10G/4.96G [00:48<00:26, 71.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  63% 3.11G/4.96G [00:48<00:27, 66.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  63% 3.12G/4.96G [00:48<00:26, 68.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  63% 3.14G/4.96G [00:48<00:26, 68.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  63% 3.15G/4.96G [00:48<00:29, 61.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  64% 3.16G/4.96G [00:48<00:27, 64.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  64% 3.17G/4.96G [00:49<00:26, 67.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  64% 3.18G/4.96G [00:49<00:27, 65.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  64% 3.19G/4.96G [00:49<00:26, 66.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  64% 3.20G/4.96G [00:49<00:27, 63.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  65% 3.21G/4.96G [00:49<00:28, 62.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  65% 3.22G/4.96G [00:49<00:27, 64.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  65% 3.23G/4.96G [00:50<00:26, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  65% 3.24G/4.96G [00:50<00:28, 59.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  66% 3.25G/4.96G [00:50<00:27, 62.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  66% 3.26G/4.96G [00:50<00:27, 61.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  66% 3.27G/4.96G [00:50<00:26, 63.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  66% 3.28G/4.96G [00:50<00:27, 62.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  66% 3.29G/4.96G [00:51<00:26, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  67% 3.30G/4.96G [00:51<00:26, 63.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  67% 3.31G/4.96G [00:51<00:26, 62.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  67% 3.32G/4.96G [00:51<00:26, 62.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  67% 3.33G/4.96G [00:51<00:25, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  67% 3.34G/4.96G [00:51<00:23, 67.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  68% 3.36G/4.96G [00:52<00:25, 64.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  68% 3.37G/4.96G [00:52<00:23, 67.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  68% 3.38G/4.96G [00:52<00:22, 69.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  68% 3.39G/4.96G [00:52<00:23, 67.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  68% 3.40G/4.96G [00:52<00:22, 69.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  69% 3.41G/4.96G [00:52<00:22, 68.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  69% 3.42G/4.96G [00:52<00:22, 68.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  69% 3.43G/4.96G [00:53<00:22, 69.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  69% 3.44G/4.96G [00:53<00:21, 70.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  70% 3.45G/4.96G [00:53<00:22, 68.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  70% 3.46G/4.96G [00:53<00:21, 68.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  70% 3.47G/4.96G [00:53<00:21, 68.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  70% 3.48G/4.96G [00:53<00:21, 67.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  70% 3.49G/4.96G [00:54<00:22, 64.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  71% 3.50G/4.96G [00:54<00:22, 64.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  71% 3.51G/4.96G [00:54<00:22, 63.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  71% 3.52G/4.96G [00:54<00:21, 65.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  71% 3.53G/4.96G [00:54<00:21, 67.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  71% 3.54G/4.96G [00:54<00:21, 67.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  72% 3.55G/4.96G [00:54<00:22, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  72% 3.57G/4.96G [00:55<00:22, 62.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  72% 3.58G/4.96G [00:55<00:23, 57.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  72% 3.59G/4.96G [00:55<00:22, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  72% 3.60G/4.96G [00:55<00:21, 62.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  73% 3.61G/4.96G [00:55<00:20, 65.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  73% 3.62G/4.96G [00:55<00:19, 68.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  73% 3.63G/4.96G [00:56<00:21, 60.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  73% 3.64G/4.96G [00:56<00:21, 61.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  74% 3.65G/4.96G [00:56<00:20, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  74% 3.66G/4.96G [00:56<00:19, 65.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  74% 3.67G/4.96G [00:56<00:19, 67.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  74% 3.68G/4.96G [00:57<00:23, 54.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  74% 3.69G/4.96G [00:57<00:22, 57.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  75% 3.70G/4.96G [00:57<00:22, 57.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  75% 3.71G/4.96G [00:57<00:20, 61.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  75% 3.72G/4.96G [00:57<00:19, 63.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  75% 3.73G/4.96G [00:58<00:24, 50.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  76% 3.75G/4.96G [00:58<00:17, 70.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  76% 3.76G/4.96G [00:58<00:16, 72.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  76% 3.77G/4.96G [00:58<00:16, 72.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  76% 3.79G/4.96G [00:58<00:17, 67.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  76% 3.80G/4.96G [00:58<00:17, 67.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  77% 3.81G/4.96G [00:58<00:17, 66.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  77% 3.82G/4.96G [00:59<00:16, 68.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  77% 3.83G/4.96G [00:59<00:17, 66.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  77% 3.84G/4.96G [00:59<00:16, 66.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  78% 3.85G/4.96G [00:59<00:16, 65.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  78% 3.86G/4.96G [00:59<00:16, 68.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  78% 3.87G/4.96G [00:59<00:15, 68.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  78% 3.88G/4.96G [01:00<00:15, 68.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  78% 3.89G/4.96G [01:00<00:14, 71.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  79% 3.90G/4.96G [01:00<00:15, 69.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  79% 3.91G/4.96G [01:00<00:15, 69.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  79% 3.92G/4.96G [01:00<00:16, 62.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  79% 3.93G/4.96G [01:00<00:16, 61.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  79% 3.94G/4.96G [01:00<00:15, 64.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  80% 3.95G/4.96G [01:01<00:15, 66.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  80% 3.96G/4.96G [01:01<00:14, 67.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  80% 3.97G/4.96G [01:01<00:14, 69.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  80% 3.98G/4.96G [01:01<00:13, 70.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  81% 4.00G/4.96G [01:01<00:13, 71.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  81% 4.01G/4.96G [01:01<00:14, 66.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  81% 4.02G/4.96G [01:02<00:13, 68.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  81% 4.03G/4.96G [01:02<00:13, 70.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  81% 4.04G/4.96G [01:02<00:12, 72.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  82% 4.05G/4.96G [01:02<00:12, 71.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  82% 4.06G/4.96G [01:02<00:12, 71.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  82% 4.07G/4.96G [01:02<00:12, 71.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  82% 4.08G/4.96G [01:02<00:13, 67.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  82% 4.09G/4.96G [01:03<00:12, 68.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  83% 4.10G/4.96G [01:03<00:12, 70.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  83% 4.11G/4.96G [01:03<00:12, 70.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  83% 4.12G/4.96G [01:03<00:11, 72.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  83% 4.13G/4.96G [01:03<00:12, 68.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  83% 4.14G/4.96G [01:03<00:11, 69.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  84% 4.15G/4.96G [01:03<00:11, 68.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  84% 4.16G/4.96G [01:04<00:12, 65.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  84% 4.17G/4.96G [01:04<00:12, 65.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  84% 4.18G/4.96G [01:04<00:13, 57.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  85% 4.19G/4.96G [01:04<00:13, 56.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  85% 4.20G/4.96G [01:04<00:12, 58.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  85% 4.22G/4.96G [01:05<00:12, 62.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  85% 4.23G/4.96G [01:05<00:11, 64.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  85% 4.24G/4.96G [01:05<00:10, 66.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  86% 4.25G/4.96G [01:05<00:10, 65.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  86% 4.26G/4.96G [01:05<00:10, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  86% 4.27G/4.96G [01:05<00:10, 66.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  86% 4.28G/4.96G [01:05<00:10, 66.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  86% 4.29G/4.96G [01:06<00:09, 68.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  87% 4.30G/4.96G [01:06<00:09, 68.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  87% 4.31G/4.96G [01:06<00:10, 64.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  87% 4.32G/4.96G [01:06<00:09, 67.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  87% 4.33G/4.96G [01:06<00:09, 67.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  87% 4.34G/4.96G [01:06<00:08, 69.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  88% 4.35G/4.96G [01:07<00:08, 69.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  88% 4.36G/4.96G [01:07<00:08, 67.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  88% 4.37G/4.96G [01:07<00:08, 70.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  88% 4.38G/4.96G [01:07<00:08, 70.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  89% 4.39G/4.96G [01:07<00:08, 70.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  89% 4.40G/4.96G [01:07<00:08, 65.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  89% 4.41G/4.96G [01:07<00:08, 67.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  89% 4.42G/4.96G [01:08<00:07, 71.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  89% 4.44G/4.96G [01:08<00:07, 71.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  90% 4.45G/4.96G [01:08<00:07, 69.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  90% 4.46G/4.96G [01:08<00:07, 69.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  90% 4.47G/4.96G [01:08<00:07, 67.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  90% 4.48G/4.96G [01:08<00:07, 67.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  90% 4.49G/4.96G [01:09<00:08, 59.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  91% 4.50G/4.96G [01:09<00:08, 54.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  91% 4.51G/4.96G [01:09<00:08, 56.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  91% 4.52G/4.96G [01:09<00:07, 59.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  91% 4.53G/4.96G [01:09<00:07, 61.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  92% 4.54G/4.96G [01:10<00:06, 61.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  92% 4.55G/4.96G [01:10<00:06, 62.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  92% 4.56G/4.96G [01:10<00:06, 64.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  92% 4.57G/4.96G [01:10<00:06, 62.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  92% 4.58G/4.96G [01:10<00:05, 63.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  93% 4.59G/4.96G [01:10<00:05, 64.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  93% 4.60G/4.96G [01:10<00:05, 64.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  93% 4.61G/4.96G [01:11<00:06, 53.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  93% 4.63G/4.96G [01:11<00:04, 68.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  94% 4.65G/4.96G [01:11<00:04, 64.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  94% 4.66G/4.96G [01:11<00:04, 65.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  94% 4.67G/4.96G [01:11<00:04, 64.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  94% 4.68G/4.96G [01:12<00:04, 63.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  94% 4.69G/4.96G [01:12<00:04, 60.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  95% 4.70G/4.96G [01:12<00:04, 63.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  95% 4.71G/4.96G [01:12<00:03, 65.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  95% 4.72G/4.96G [01:12<00:03, 62.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  95% 4.73G/4.96G [01:12<00:03, 64.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  96% 4.74G/4.96G [01:13<00:03, 64.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  96% 4.75G/4.96G [01:13<00:03, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  96% 4.76G/4.96G [01:13<00:03, 65.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  96% 4.77G/4.96G [01:13<00:02, 65.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  96% 4.78G/4.96G [01:13<00:02, 63.0MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  97% 4.79G/4.96G [01:13<00:02, 62.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  97% 4.80G/4.96G [01:14<00:02, 58.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  97% 4.81G/4.96G [01:14<00:02, 58.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  97% 4.82G/4.96G [01:14<00:02, 54.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  97% 4.83G/4.96G [01:14<00:02, 51.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  98% 4.84G/4.96G [01:14<00:02, 54.7MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  98% 4.85G/4.96G [01:15<00:01, 56.4MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  98% 4.87G/4.96G [01:15<00:01, 61.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  98% 4.88G/4.96G [01:15<00:01, 64.8MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  98% 4.89G/4.96G [01:15<00:01, 64.5MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  99% 4.90G/4.96G [01:15<00:01, 62.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  99% 4.91G/4.96G [01:15<00:00, 60.9MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  99% 4.92G/4.96G [01:16<00:00, 50.6MB/s]\u001b[A\n","model-00001-of-00006.safetensors:  99% 4.93G/4.96G [01:16<00:00, 55.1MB/s]\u001b[A\n","model-00001-of-00006.safetensors: 100% 4.94G/4.96G [01:16<00:00, 57.3MB/s]\u001b[A\n","model-00001-of-00006.safetensors: 100% 4.95G/4.96G [01:16<00:00, 59.2MB/s]\u001b[A\n","model-00001-of-00006.safetensors: 100% 4.96G/4.96G [01:16<00:00, 64.5MB/s]\n","Downloading shards:  17% 1/6 [01:17<06:26, 77.39s/it]\n","model-00002-of-00006.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00006.safetensors:   0% 10.5M/4.97G [00:00<01:12, 68.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   0% 21.0M/4.97G [00:00<01:41, 48.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   1% 31.5M/4.97G [00:00<01:27, 56.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   1% 41.9M/4.97G [00:00<01:25, 57.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   1% 52.4M/4.97G [00:00<01:24, 58.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   1% 62.9M/4.97G [00:01<01:30, 54.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   1% 73.4M/4.97G [00:01<01:25, 57.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   2% 83.9M/4.97G [00:01<01:22, 58.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   2% 94.4M/4.97G [00:01<01:17, 63.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   2% 105M/4.97G [00:01<01:16, 63.7MB/s] \u001b[A\n","model-00002-of-00006.safetensors:   2% 115M/4.97G [00:01<01:13, 66.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   3% 126M/4.97G [00:02<01:13, 66.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   3% 136M/4.97G [00:02<01:14, 64.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   3% 147M/4.97G [00:02<01:13, 65.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   3% 157M/4.97G [00:02<01:26, 55.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   3% 168M/4.97G [00:02<01:25, 56.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   4% 178M/4.97G [00:02<01:21, 58.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   4% 189M/4.97G [00:03<01:20, 59.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   4% 199M/4.97G [00:03<01:16, 62.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   4% 210M/4.97G [00:03<01:11, 66.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   4% 220M/4.97G [00:03<01:12, 65.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   5% 231M/4.97G [00:03<01:16, 62.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   5% 241M/4.97G [00:03<01:15, 62.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   5% 252M/4.97G [00:04<01:13, 63.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   5% 262M/4.97G [00:04<01:10, 66.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   5% 273M/4.97G [00:04<01:15, 62.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   6% 283M/4.97G [00:04<01:24, 55.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   6% 294M/4.97G [00:04<01:26, 54.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   6% 304M/4.97G [00:05<01:24, 55.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   6% 315M/4.97G [00:06<03:58, 19.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   7% 336M/4.97G [00:06<02:28, 31.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   7% 346M/4.97G [00:06<02:08, 36.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   7% 357M/4.97G [00:06<01:52, 40.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   7% 367M/4.97G [00:07<01:41, 45.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   8% 377M/4.97G [00:07<01:49, 42.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   8% 398M/4.97G [00:07<01:28, 51.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   8% 409M/4.97G [00:07<01:22, 55.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   8% 419M/4.97G [00:07<01:18, 58.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   9% 430M/4.97G [00:08<01:15, 59.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   9% 440M/4.97G [00:08<01:10, 64.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   9% 451M/4.97G [00:08<01:09, 65.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   9% 461M/4.97G [00:08<01:06, 68.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:   9% 472M/4.97G [00:08<01:06, 67.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  10% 482M/4.97G [00:08<01:04, 69.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  10% 493M/4.97G [00:09<01:04, 69.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  10% 503M/4.97G [00:09<01:04, 69.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  10% 514M/4.97G [00:09<01:02, 71.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  11% 524M/4.97G [00:09<01:06, 67.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  11% 535M/4.97G [00:09<01:05, 67.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  11% 545M/4.97G [00:09<01:05, 67.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  11% 556M/4.97G [00:09<01:04, 68.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  11% 566M/4.97G [00:10<01:05, 67.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  12% 577M/4.97G [00:10<01:04, 68.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  12% 587M/4.97G [00:10<01:02, 69.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  12% 598M/4.97G [00:10<01:04, 67.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  12% 608M/4.97G [00:10<01:06, 65.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  12% 619M/4.97G [00:10<01:07, 64.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  13% 629M/4.97G [00:11<01:09, 62.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  13% 640M/4.97G [00:11<01:10, 61.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  13% 650M/4.97G [00:11<01:09, 62.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  13% 661M/4.97G [00:11<01:09, 61.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  14% 671M/4.97G [00:11<01:11, 60.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  14% 682M/4.97G [00:11<01:11, 60.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  14% 692M/4.97G [00:12<01:12, 58.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  14% 703M/4.97G [00:12<01:08, 62.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  14% 713M/4.97G [00:12<01:05, 64.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  15% 724M/4.97G [00:12<01:04, 65.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  15% 734M/4.97G [00:12<01:09, 60.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  15% 744M/4.97G [00:13<01:16, 55.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  15% 755M/4.97G [00:13<01:13, 57.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  15% 765M/4.97G [00:13<01:09, 60.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  16% 776M/4.97G [00:13<01:07, 62.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  16% 786M/4.97G [00:13<01:08, 61.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  16% 797M/4.97G [00:13<01:07, 61.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  16% 807M/4.97G [00:14<01:08, 60.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  16% 818M/4.97G [00:14<01:07, 61.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  17% 828M/4.97G [00:14<01:11, 57.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  17% 839M/4.97G [00:14<01:08, 60.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  17% 849M/4.97G [00:14<01:09, 59.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  17% 860M/4.97G [00:14<01:07, 60.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  18% 870M/4.97G [00:15<01:07, 60.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  18% 881M/4.97G [00:15<01:10, 58.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  18% 891M/4.97G [00:15<01:11, 57.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  18% 902M/4.97G [00:15<01:10, 57.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  18% 912M/4.97G [00:15<01:11, 56.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  19% 923M/4.97G [00:15<01:08, 59.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  19% 933M/4.97G [00:16<01:08, 58.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  19% 944M/4.97G [00:16<01:15, 53.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  19% 954M/4.97G [00:16<01:10, 56.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  19% 965M/4.97G [00:16<01:12, 55.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  20% 975M/4.97G [00:16<01:07, 59.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  20% 986M/4.97G [00:17<01:06, 59.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  20% 996M/4.97G [00:17<01:09, 57.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  20% 1.01G/4.97G [00:17<01:06, 59.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  20% 1.02G/4.97G [00:17<01:18, 50.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  21% 1.04G/4.97G [00:17<00:56, 70.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  21% 1.05G/4.97G [00:18<00:54, 71.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  21% 1.06G/4.97G [00:18<00:55, 70.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  22% 1.07G/4.97G [00:18<00:55, 69.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  22% 1.08G/4.97G [00:18<00:54, 71.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  22% 1.09G/4.97G [00:18<00:54, 70.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  22% 1.10G/4.97G [00:18<00:58, 66.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  22% 1.11G/4.97G [00:18<00:55, 69.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  23% 1.12G/4.97G [00:19<00:53, 72.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  23% 1.13G/4.97G [00:19<00:52, 73.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  23% 1.14G/4.97G [00:19<00:52, 73.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  23% 1.15G/4.97G [00:19<00:52, 72.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  23% 1.16G/4.97G [00:19<00:54, 70.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  24% 1.17G/4.97G [00:19<00:55, 68.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  24% 1.18G/4.97G [00:19<00:54, 70.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  24% 1.20G/4.97G [00:20<00:55, 67.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  24% 1.21G/4.97G [00:20<00:58, 64.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  24% 1.22G/4.97G [00:20<00:55, 67.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  25% 1.23G/4.97G [00:20<00:54, 68.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  25% 1.24G/4.97G [00:20<00:55, 66.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  25% 1.25G/4.97G [00:20<00:53, 70.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  25% 1.26G/4.97G [00:21<00:57, 65.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  26% 1.27G/4.97G [00:21<00:55, 66.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  26% 1.28G/4.97G [00:21<00:54, 67.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  26% 1.29G/4.97G [00:21<00:52, 70.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  26% 1.30G/4.97G [00:21<00:51, 71.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  26% 1.31G/4.97G [00:21<00:50, 71.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  27% 1.32G/4.97G [00:21<00:49, 74.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  27% 1.33G/4.97G [00:22<00:48, 75.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  27% 1.34G/4.97G [00:22<00:46, 77.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  27% 1.35G/4.97G [00:22<00:47, 76.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  27% 1.36G/4.97G [00:22<00:47, 75.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  28% 1.37G/4.97G [00:22<00:46, 77.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  28% 1.38G/4.97G [00:22<00:45, 78.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  28% 1.39G/4.97G [00:22<00:45, 79.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  28% 1.41G/4.97G [00:23<00:47, 75.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  28% 1.42G/4.97G [00:23<00:45, 77.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  29% 1.43G/4.97G [00:23<00:45, 77.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  29% 1.44G/4.97G [00:23<00:45, 77.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  29% 1.45G/4.97G [00:23<00:45, 77.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  29% 1.46G/4.97G [00:23<00:45, 77.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  30% 1.47G/4.97G [00:23<00:45, 77.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  30% 1.48G/4.97G [00:23<00:45, 76.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  30% 1.49G/4.97G [00:24<00:46, 75.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  30% 1.50G/4.97G [00:24<00:49, 70.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  30% 1.51G/4.97G [00:24<00:48, 71.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  31% 1.52G/4.97G [00:24<00:48, 70.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  31% 1.53G/4.97G [00:24<00:48, 71.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  31% 1.54G/4.97G [00:24<00:48, 71.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  31% 1.55G/4.97G [00:25<00:48, 70.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  31% 1.56G/4.97G [00:25<00:50, 67.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  32% 1.57G/4.97G [00:25<00:52, 64.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  32% 1.58G/4.97G [00:27<03:48, 14.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  32% 1.60G/4.97G [00:27<02:12, 25.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  32% 1.61G/4.97G [00:27<01:56, 28.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  33% 1.63G/4.97G [00:27<01:44, 32.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  33% 1.64G/4.97G [00:28<01:30, 36.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  33% 1.65G/4.97G [00:28<01:17, 42.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  33% 1.66G/4.97G [00:28<01:09, 48.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  34% 1.67G/4.97G [00:28<01:04, 51.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  34% 1.68G/4.97G [00:28<01:02, 52.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  34% 1.69G/4.97G [00:28<00:58, 56.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  34% 1.70G/4.97G [00:29<00:56, 57.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  34% 1.71G/4.97G [00:29<00:54, 60.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  35% 1.72G/4.97G [00:29<00:52, 61.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  35% 1.73G/4.97G [00:29<00:50, 63.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  35% 1.74G/4.97G [00:29<00:56, 57.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  35% 1.75G/4.97G [00:29<00:56, 57.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  35% 1.76G/4.97G [00:30<00:52, 60.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  36% 1.77G/4.97G [00:30<00:50, 63.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  36% 1.78G/4.97G [00:30<00:48, 65.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  36% 1.79G/4.97G [00:30<00:46, 68.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  36% 1.80G/4.97G [00:30<00:55, 57.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  37% 1.82G/4.97G [00:31<00:45, 68.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  37% 1.84G/4.97G [00:31<00:45, 68.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  37% 1.85G/4.97G [00:31<00:45, 68.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  37% 1.86G/4.97G [00:31<00:45, 67.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  38% 1.87G/4.97G [00:31<00:48, 64.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  38% 1.88G/4.97G [00:31<00:47, 65.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  38% 1.89G/4.97G [00:31<00:46, 65.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  38% 1.90G/4.97G [00:32<00:48, 63.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  38% 1.91G/4.97G [00:32<00:47, 65.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  39% 1.92G/4.97G [00:32<00:46, 66.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  39% 1.93G/4.97G [00:32<00:47, 63.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  39% 1.94G/4.97G [00:32<00:46, 64.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  39% 1.95G/4.97G [00:32<00:47, 63.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  39% 1.96G/4.97G [00:33<00:47, 63.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  40% 1.97G/4.97G [00:33<00:50, 59.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  40% 1.98G/4.97G [00:33<00:47, 62.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  40% 1.99G/4.97G [00:33<00:50, 58.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  40% 2.00G/4.97G [00:33<00:48, 61.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  41% 2.01G/4.97G [00:34<00:48, 61.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  41% 2.02G/4.97G [00:34<00:46, 63.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  41% 2.03G/4.97G [00:34<00:46, 63.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  41% 2.04G/4.97G [00:34<00:45, 64.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  41% 2.06G/4.97G [00:34<00:44, 65.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  42% 2.07G/4.97G [00:34<00:45, 64.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  42% 2.08G/4.97G [00:34<00:45, 63.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  42% 2.09G/4.97G [00:35<00:44, 65.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  42% 2.10G/4.97G [00:35<00:43, 66.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  42% 2.11G/4.97G [00:35<00:41, 69.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  43% 2.12G/4.97G [00:35<00:41, 69.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  43% 2.13G/4.97G [00:35<00:40, 70.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  43% 2.14G/4.97G [00:35<00:39, 71.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  43% 2.15G/4.97G [00:36<00:41, 68.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  43% 2.16G/4.97G [00:36<00:42, 65.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  44% 2.17G/4.97G [00:36<00:42, 65.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  44% 2.18G/4.97G [00:36<00:40, 68.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  44% 2.19G/4.97G [00:36<00:41, 66.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  44% 2.20G/4.97G [00:36<00:40, 68.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  45% 2.21G/4.97G [00:36<00:38, 70.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  45% 2.22G/4.97G [00:37<00:39, 70.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  45% 2.23G/4.97G [00:37<00:39, 68.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  45% 2.24G/4.97G [00:37<00:43, 62.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  45% 2.25G/4.97G [00:37<00:41, 65.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  46% 2.26G/4.97G [00:37<00:43, 62.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  46% 2.28G/4.97G [00:37<00:42, 64.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  46% 2.29G/4.97G [00:38<00:41, 64.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  46% 2.30G/4.97G [00:38<00:39, 67.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  46% 2.31G/4.97G [00:38<00:37, 71.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  47% 2.32G/4.97G [00:38<00:37, 69.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  47% 2.33G/4.97G [00:38<00:38, 68.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  47% 2.34G/4.97G [00:38<00:38, 68.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  47% 2.35G/4.97G [00:38<00:37, 69.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  47% 2.36G/4.97G [00:39<00:37, 70.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  48% 2.37G/4.97G [00:39<00:36, 70.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  48% 2.38G/4.97G [00:39<00:40, 64.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  48% 2.39G/4.97G [00:39<00:37, 68.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  48% 2.40G/4.97G [00:39<00:37, 68.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  49% 2.41G/4.97G [00:39<00:35, 71.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  49% 2.42G/4.97G [00:40<00:36, 70.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  49% 2.43G/4.97G [00:40<00:38, 65.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  49% 2.44G/4.97G [00:40<00:36, 68.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  49% 2.45G/4.97G [00:40<00:37, 66.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  50% 2.46G/4.97G [00:40<00:36, 68.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  50% 2.47G/4.97G [00:40<00:39, 63.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  50% 2.49G/4.97G [00:41<00:40, 61.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  50% 2.50G/4.97G [00:41<00:38, 63.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  50% 2.51G/4.97G [00:41<00:36, 67.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  51% 2.52G/4.97G [00:41<00:35, 68.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  51% 2.53G/4.97G [00:41<00:37, 65.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  51% 2.54G/4.97G [00:41<00:39, 62.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  51% 2.55G/4.97G [00:42<00:39, 60.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  51% 2.56G/4.97G [00:42<00:38, 62.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  52% 2.57G/4.97G [00:42<00:39, 61.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  52% 2.58G/4.97G [00:42<00:37, 63.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  52% 2.59G/4.97G [00:42<00:39, 59.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  52% 2.60G/4.97G [00:43<00:48, 48.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  53% 2.62G/4.97G [00:43<00:33, 70.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  53% 2.63G/4.97G [00:43<00:31, 73.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  53% 2.64G/4.97G [00:43<00:33, 70.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  53% 2.65G/4.97G [00:43<00:33, 68.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  54% 2.66G/4.97G [00:43<00:32, 69.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  54% 2.67G/4.97G [00:43<00:32, 70.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  54% 2.68G/4.97G [00:44<00:33, 69.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  54% 2.69G/4.97G [00:44<00:34, 65.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  54% 2.71G/4.97G [00:44<00:35, 63.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  55% 2.72G/4.97G [00:44<00:33, 66.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  55% 2.73G/4.97G [00:44<00:33, 67.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  55% 2.74G/4.97G [00:44<00:32, 68.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  55% 2.75G/4.97G [00:45<00:34, 64.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  55% 2.76G/4.97G [00:45<00:32, 67.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  56% 2.77G/4.97G [00:45<00:33, 64.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  56% 2.78G/4.97G [00:45<00:32, 68.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  56% 2.79G/4.97G [00:45<00:33, 64.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  56% 2.80G/4.97G [00:45<00:35, 61.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  57% 2.81G/4.97G [00:46<00:34, 63.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  57% 2.82G/4.97G [00:46<00:32, 66.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  57% 2.83G/4.97G [00:46<00:33, 64.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  57% 2.84G/4.97G [00:46<00:33, 63.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  57% 2.85G/4.97G [00:46<00:31, 66.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  58% 2.86G/4.97G [00:46<00:32, 65.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  58% 2.87G/4.97G [00:46<00:30, 68.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  58% 2.88G/4.97G [00:47<00:32, 65.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  58% 2.89G/4.97G [00:47<00:31, 65.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  58% 2.90G/4.97G [00:47<00:33, 60.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  59% 2.92G/4.97G [00:47<00:38, 53.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  59% 2.93G/4.97G [00:47<00:34, 58.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  59% 2.94G/4.97G [00:48<00:34, 59.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  59% 2.95G/4.97G [00:48<00:32, 61.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  59% 2.96G/4.97G [00:48<00:31, 64.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  60% 2.97G/4.97G [00:48<00:30, 64.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  60% 2.98G/4.97G [00:48<00:29, 66.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  60% 2.99G/4.97G [00:48<00:29, 66.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  60% 3.00G/4.97G [00:49<00:31, 62.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  61% 3.01G/4.97G [00:49<00:31, 62.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  61% 3.02G/4.97G [00:49<00:30, 63.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  61% 3.03G/4.97G [00:49<00:32, 59.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  61% 3.04G/4.97G [00:49<00:30, 62.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  61% 3.05G/4.97G [00:49<00:31, 61.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  62% 3.06G/4.97G [00:50<00:30, 62.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  62% 3.07G/4.97G [00:50<00:29, 64.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  62% 3.08G/4.97G [00:50<00:28, 65.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  62% 3.09G/4.97G [00:50<00:29, 63.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  62% 3.10G/4.97G [00:50<00:31, 59.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  63% 3.11G/4.97G [00:50<00:32, 58.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  63% 3.12G/4.97G [00:51<00:31, 59.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  63% 3.14G/4.97G [00:51<00:29, 62.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  63% 3.15G/4.97G [00:51<00:29, 62.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  63% 3.16G/4.97G [00:51<00:28, 64.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  64% 3.17G/4.97G [00:51<00:27, 65.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  64% 3.18G/4.97G [00:51<00:26, 67.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  64% 3.19G/4.97G [00:52<00:27, 64.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  64% 3.20G/4.97G [00:52<00:27, 63.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  65% 3.21G/4.97G [00:52<00:29, 60.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  65% 3.22G/4.97G [00:52<00:31, 54.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  65% 3.23G/4.97G [00:52<00:30, 56.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  65% 3.24G/4.97G [00:52<00:28, 60.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  65% 3.25G/4.97G [00:53<00:27, 61.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  66% 3.26G/4.97G [00:53<00:26, 65.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  66% 3.27G/4.97G [00:53<00:24, 69.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  66% 3.28G/4.97G [00:53<00:24, 68.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  66% 3.29G/4.97G [00:53<00:24, 68.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  66% 3.30G/4.97G [00:53<00:25, 66.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  67% 3.31G/4.97G [00:54<00:25, 65.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  67% 3.32G/4.97G [00:54<00:24, 67.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  67% 3.33G/4.97G [00:54<00:25, 64.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  67% 3.34G/4.97G [00:54<00:24, 66.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  68% 3.36G/4.97G [00:54<00:23, 68.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  68% 3.37G/4.97G [00:54<00:26, 61.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  68% 3.38G/4.97G [00:54<00:24, 64.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  68% 3.39G/4.97G [00:55<00:24, 64.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  68% 3.40G/4.97G [00:55<00:26, 59.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  69% 3.41G/4.97G [00:55<00:25, 60.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  69% 3.42G/4.97G [00:55<00:26, 57.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  69% 3.43G/4.97G [00:55<00:25, 60.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  69% 3.44G/4.97G [00:56<00:24, 62.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  69% 3.45G/4.97G [00:56<00:23, 65.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  70% 3.46G/4.97G [00:56<00:23, 65.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  70% 3.47G/4.97G [00:56<00:23, 62.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  70% 3.48G/4.97G [00:56<00:24, 61.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  70% 3.49G/4.97G [00:56<00:23, 61.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  70% 3.50G/4.97G [00:57<00:23, 62.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  71% 3.51G/4.97G [00:57<00:23, 63.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  71% 3.52G/4.97G [00:57<00:23, 62.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  71% 3.53G/4.97G [00:57<00:21, 66.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  71% 3.54G/4.97G [00:57<00:22, 62.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  72% 3.55G/4.97G [00:58<00:28, 48.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  72% 3.58G/4.97G [00:58<00:18, 74.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  72% 3.59G/4.97G [00:58<00:21, 64.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  72% 3.60G/4.97G [00:58<00:21, 63.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  73% 3.61G/4.97G [00:58<00:20, 65.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  73% 3.62G/4.97G [00:58<00:20, 65.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  73% 3.63G/4.97G [00:59<00:21, 63.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  73% 3.64G/4.97G [00:59<00:21, 61.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  73% 3.65G/4.97G [00:59<00:21, 61.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  74% 3.66G/4.97G [00:59<00:21, 62.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  74% 3.67G/4.97G [00:59<00:20, 62.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  74% 3.68G/4.97G [00:59<00:20, 64.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  74% 3.69G/4.97G [01:00<00:20, 63.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  74% 3.70G/4.97G [01:00<00:19, 63.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  75% 3.71G/4.97G [01:00<00:19, 65.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  75% 3.72G/4.97G [01:00<00:19, 64.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  75% 3.73G/4.97G [01:00<00:18, 66.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  75% 3.74G/4.97G [01:00<00:18, 66.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  76% 3.75G/4.97G [01:00<00:18, 65.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  76% 3.76G/4.97G [01:01<00:18, 65.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  76% 3.77G/4.97G [01:01<00:17, 67.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  76% 3.79G/4.97G [01:01<00:17, 68.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  76% 3.80G/4.97G [01:01<00:16, 69.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  77% 3.81G/4.97G [01:01<00:16, 70.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  77% 3.82G/4.97G [01:01<00:17, 67.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  77% 3.83G/4.97G [01:02<00:18, 60.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  77% 3.84G/4.97G [01:02<00:20, 56.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  77% 3.85G/4.97G [01:02<00:19, 57.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  78% 3.86G/4.97G [01:02<00:18, 59.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  78% 3.87G/4.97G [01:02<00:17, 61.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  78% 3.88G/4.97G [01:02<00:16, 65.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  78% 3.89G/4.97G [01:03<00:17, 61.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  78% 3.90G/4.97G [01:03<00:16, 64.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  79% 3.91G/4.97G [01:03<00:15, 66.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  79% 3.92G/4.97G [01:03<00:15, 66.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  79% 3.93G/4.97G [01:03<00:15, 67.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  79% 3.94G/4.97G [01:03<00:15, 64.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  80% 3.95G/4.97G [01:04<00:17, 59.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  80% 3.96G/4.97G [01:04<00:18, 55.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  80% 3.97G/4.97G [01:04<00:18, 55.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  80% 3.98G/4.97G [01:04<00:17, 57.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  80% 4.00G/4.97G [01:04<00:16, 58.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  81% 4.01G/4.97G [01:05<00:15, 62.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  81% 4.02G/4.97G [01:05<00:16, 58.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  81% 4.03G/4.97G [01:05<00:15, 61.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  81% 4.04G/4.97G [01:05<00:14, 62.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  81% 4.05G/4.97G [01:05<00:14, 65.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  82% 4.06G/4.97G [01:05<00:13, 68.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  82% 4.07G/4.97G [01:05<00:12, 70.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  82% 4.08G/4.97G [01:06<00:12, 70.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  82% 4.09G/4.97G [01:06<00:12, 71.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  82% 4.10G/4.97G [01:06<00:12, 71.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  83% 4.11G/4.97G [01:06<00:12, 71.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  83% 4.12G/4.97G [01:06<00:11, 73.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  83% 4.13G/4.97G [01:06<00:15, 55.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  84% 4.15G/4.97G [01:07<00:11, 69.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  84% 4.16G/4.97G [01:07<00:11, 69.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  84% 4.17G/4.97G [01:07<00:11, 67.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  84% 4.18G/4.97G [01:07<00:11, 68.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  84% 4.19G/4.97G [01:07<00:11, 70.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  85% 4.20G/4.97G [01:07<00:11, 69.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  85% 4.22G/4.97G [01:08<00:10, 70.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  85% 4.23G/4.97G [01:08<00:10, 69.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  85% 4.24G/4.97G [01:08<00:11, 63.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  85% 4.25G/4.97G [01:08<00:11, 63.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  86% 4.26G/4.97G [01:08<00:11, 64.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  86% 4.27G/4.97G [01:08<00:10, 67.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  86% 4.28G/4.97G [01:09<00:10, 65.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  86% 4.29G/4.97G [01:09<00:10, 66.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  86% 4.30G/4.97G [01:09<00:10, 66.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  87% 4.31G/4.97G [01:09<00:10, 65.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  87% 4.32G/4.97G [01:09<00:10, 61.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  87% 4.33G/4.97G [01:09<00:10, 61.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  87% 4.34G/4.97G [01:10<00:10, 59.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  88% 4.35G/4.97G [01:10<00:10, 59.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  88% 4.36G/4.97G [01:10<00:10, 60.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  88% 4.37G/4.97G [01:10<00:09, 60.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  88% 4.38G/4.97G [01:10<00:09, 62.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  88% 4.39G/4.97G [01:10<00:08, 64.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  89% 4.40G/4.97G [01:11<00:08, 64.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  89% 4.41G/4.97G [01:11<00:08, 67.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  89% 4.42G/4.97G [01:11<00:08, 61.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  89% 4.44G/4.97G [01:11<00:08, 60.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  89% 4.45G/4.97G [01:11<00:08, 62.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  90% 4.46G/4.97G [01:11<00:08, 62.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  90% 4.47G/4.97G [01:12<00:08, 61.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  90% 4.48G/4.97G [01:12<00:07, 65.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  90% 4.49G/4.97G [01:12<00:07, 67.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  91% 4.50G/4.97G [01:12<00:07, 64.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  91% 4.51G/4.97G [01:12<00:07, 63.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  91% 4.52G/4.97G [01:12<00:06, 65.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  91% 4.53G/4.97G [01:13<00:06, 68.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  91% 4.54G/4.97G [01:13<00:06, 67.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  92% 4.55G/4.97G [01:13<00:06, 68.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  92% 4.56G/4.97G [01:13<00:06, 65.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  92% 4.57G/4.97G [01:13<00:06, 65.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  92% 4.58G/4.97G [01:13<00:05, 67.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  92% 4.59G/4.97G [01:13<00:05, 68.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  93% 4.60G/4.97G [01:14<00:05, 68.5MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  93% 4.61G/4.97G [01:14<00:05, 69.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  93% 4.62G/4.97G [01:14<00:05, 62.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  93% 4.63G/4.97G [01:14<00:05, 65.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  93% 4.65G/4.97G [01:14<00:05, 60.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  94% 4.66G/4.97G [01:15<00:05, 56.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  94% 4.67G/4.97G [01:15<00:04, 60.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  94% 4.68G/4.97G [01:15<00:04, 61.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  94% 4.69G/4.97G [01:15<00:04, 61.7MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  95% 4.70G/4.97G [01:15<00:04, 60.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  95% 4.71G/4.97G [01:16<00:05, 46.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  95% 4.73G/4.97G [01:16<00:03, 69.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  95% 4.74G/4.97G [01:17<00:10, 22.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  96% 4.75G/4.97G [01:18<00:12, 17.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  96% 4.77G/4.97G [01:18<00:07, 26.9MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  96% 4.78G/4.97G [01:18<00:06, 31.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  96% 4.79G/4.97G [01:19<00:05, 35.6MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  97% 4.80G/4.97G [01:19<00:04, 40.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  97% 4.81G/4.97G [01:19<00:03, 46.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  97% 4.82G/4.97G [01:19<00:02, 51.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  97% 4.83G/4.97G [01:19<00:02, 56.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  97% 4.84G/4.97G [01:19<00:02, 60.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  98% 4.85G/4.97G [01:19<00:01, 63.2MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  98% 4.87G/4.97G [01:20<00:01, 65.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  98% 4.88G/4.97G [01:20<00:01, 65.1MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  98% 4.89G/4.97G [01:20<00:01, 63.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  99% 4.90G/4.97G [01:20<00:01, 64.4MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  99% 4.91G/4.97G [01:20<00:00, 64.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  99% 4.92G/4.97G [01:20<00:00, 62.3MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  99% 4.93G/4.97G [01:21<00:00, 57.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors:  99% 4.94G/4.97G [01:21<00:00, 56.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors: 100% 4.95G/4.97G [01:21<00:00, 58.0MB/s]\u001b[A\n","model-00002-of-00006.safetensors: 100% 4.96G/4.97G [01:21<00:00, 59.8MB/s]\u001b[A\n","model-00002-of-00006.safetensors: 100% 4.97G/4.97G [01:21<00:00, 60.7MB/s]\n","Downloading shards:  33% 2/6 [02:39<05:21, 80.33s/it]\n","model-00003-of-00006.safetensors:   0% 0.00/4.88G [00:00<?, ?B/s]\u001b[A\n","model-00003-of-00006.safetensors:   0% 10.5M/4.88G [00:00<03:04, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   0% 21.0M/4.88G [00:00<03:03, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   1% 31.5M/4.88G [00:01<03:02, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   1% 41.9M/4.88G [00:01<03:01, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   1% 52.4M/4.88G [00:01<03:01, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   1% 62.9M/4.88G [00:02<03:01, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   2% 73.4M/4.88G [00:02<03:26, 23.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   2% 83.9M/4.88G [00:03<03:17, 24.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   2% 94.4M/4.88G [00:03<03:11, 25.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   2% 105M/4.88G [00:04<03:07, 25.5MB/s] \u001b[A\n","model-00003-of-00006.safetensors:   2% 115M/4.88G [00:04<03:04, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   3% 126M/4.88G [00:04<03:02, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   3% 136M/4.88G [00:05<03:00, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   3% 147M/4.88G [00:05<02:58, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   3% 157M/4.88G [00:06<02:57, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   3% 168M/4.88G [00:06<02:56, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   4% 178M/4.88G [00:06<02:59, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   4% 189M/4.88G [00:07<03:16, 23.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   4% 199M/4.88G [00:07<03:10, 24.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   4% 210M/4.88G [00:08<03:05, 25.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   5% 220M/4.88G [00:08<03:01, 25.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   5% 231M/4.88G [00:08<02:59, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   5% 241M/4.88G [00:09<02:57, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   5% 252M/4.88G [00:09<02:57, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   5% 262M/4.88G [00:10<02:55, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   6% 273M/4.88G [00:10<02:54, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   6% 283M/4.88G [00:10<02:54, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   6% 294M/4.88G [00:11<02:52, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   6% 304M/4.88G [00:11<02:52, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   6% 315M/4.88G [00:12<02:56, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   7% 325M/4.88G [00:12<03:07, 24.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   7% 336M/4.88G [00:13<03:05, 24.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   7% 346M/4.88G [00:13<03:01, 25.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   7% 357M/4.88G [00:13<02:57, 25.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   8% 367M/4.88G [00:14<02:54, 25.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   8% 377M/4.88G [00:14<02:52, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   8% 388M/4.88G [00:15<02:51, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   8% 398M/4.88G [00:15<02:50, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   8% 409M/4.88G [00:15<02:49, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   9% 419M/4.88G [00:16<03:04, 24.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   9% 430M/4.88G [00:16<02:58, 24.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   9% 440M/4.88G [00:17<02:56, 25.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   9% 451M/4.88G [00:17<02:52, 25.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:   9% 461M/4.88G [00:17<02:49, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  10% 472M/4.88G [00:18<02:48, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  10% 482M/4.88G [00:18<02:47, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  10% 493M/4.88G [00:19<02:46, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  10% 503M/4.88G [00:19<02:45, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  11% 514M/4.88G [00:19<02:44, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  11% 524M/4.88G [00:20<02:43, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  11% 535M/4.88G [00:20<02:42, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  11% 545M/4.88G [00:21<02:42, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  11% 556M/4.88G [00:21<02:41, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  12% 566M/4.88G [00:21<02:41, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  12% 577M/4.88G [00:22<02:41, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  12% 587M/4.88G [00:22<02:40, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  12% 598M/4.88G [00:23<02:40, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  12% 608M/4.88G [00:23<02:39, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  13% 619M/4.88G [00:23<02:42, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  13% 629M/4.88G [00:24<02:43, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  13% 640M/4.88G [00:24<02:42, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  13% 650M/4.88G [00:25<02:50, 24.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  14% 661M/4.88G [00:25<02:46, 25.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  14% 671M/4.88G [00:25<02:43, 25.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  14% 682M/4.88G [00:26<02:41, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  14% 692M/4.88G [00:26<02:39, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  14% 703M/4.88G [00:27<02:37, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  15% 713M/4.88G [00:27<02:37, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  15% 724M/4.88G [00:27<02:36, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  15% 734M/4.88G [00:28<02:35, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  15% 744M/4.88G [00:28<02:34, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  15% 755M/4.88G [00:29<02:34, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  16% 765M/4.88G [00:29<02:34, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  16% 776M/4.88G [00:29<02:33, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  16% 786M/4.88G [00:30<02:33, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  16% 797M/4.88G [00:30<02:33, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  17% 807M/4.88G [00:31<02:33, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  17% 818M/4.88G [00:31<02:32, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  17% 828M/4.88G [00:31<02:31, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  17% 839M/4.88G [00:32<02:33, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  17% 849M/4.88G [00:32<02:31, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  18% 860M/4.88G [00:32<02:30, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  18% 870M/4.88G [00:33<02:30, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  18% 881M/4.88G [00:33<02:30, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  18% 891M/4.88G [00:34<02:30, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  18% 902M/4.88G [00:34<02:30, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  19% 912M/4.88G [00:34<02:29, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  19% 923M/4.88G [00:35<02:29, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  19% 933M/4.88G [00:35<02:29, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  19% 944M/4.88G [00:36<02:29, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  20% 954M/4.88G [00:36<02:32, 25.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  20% 965M/4.88G [00:37<02:34, 25.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  20% 975M/4.88G [00:37<02:31, 25.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  20% 986M/4.88G [00:37<02:29, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  20% 996M/4.88G [00:38<02:28, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  21% 1.01G/4.88G [00:38<02:27, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  21% 1.02G/4.88G [00:38<02:26, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  21% 1.03G/4.88G [00:39<02:25, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  21% 1.04G/4.88G [00:39<02:24, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  21% 1.05G/4.88G [00:40<02:24, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  22% 1.06G/4.88G [00:40<02:24, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  22% 1.07G/4.88G [00:40<02:23, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  22% 1.08G/4.88G [00:41<02:23, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  22% 1.09G/4.88G [00:41<02:22, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  23% 1.10G/4.88G [00:42<02:22, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  23% 1.11G/4.88G [00:42<02:21, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  23% 1.12G/4.88G [00:42<02:22, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  23% 1.13G/4.88G [00:43<02:21, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  23% 1.14G/4.88G [00:43<02:21, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  24% 1.15G/4.88G [00:44<02:20, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  24% 1.16G/4.88G [00:44<02:20, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  24% 1.17G/4.88G [00:44<02:19, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  24% 1.18G/4.88G [00:45<02:18, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  24% 1.20G/4.88G [00:45<02:18, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  25% 1.21G/4.88G [00:46<02:17, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  25% 1.22G/4.88G [00:46<02:17, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  25% 1.23G/4.88G [00:46<02:18, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  25% 1.24G/4.88G [00:47<02:17, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  26% 1.25G/4.88G [00:47<02:19, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  26% 1.26G/4.88G [00:48<02:19, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  26% 1.27G/4.88G [00:48<02:17, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  26% 1.28G/4.88G [00:48<02:17, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  26% 1.29G/4.88G [00:49<02:16, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  27% 1.30G/4.88G [00:49<02:16, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  27% 1.31G/4.88G [00:50<02:16, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  27% 1.32G/4.88G [00:50<02:16, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  27% 1.33G/4.88G [00:50<02:14, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  27% 1.34G/4.88G [00:51<02:14, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  28% 1.35G/4.88G [00:51<02:13, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  28% 1.36G/4.88G [00:52<02:13, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  28% 1.37G/4.88G [00:52<02:12, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  28% 1.38G/4.88G [00:52<02:11, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  29% 1.39G/4.88G [00:53<02:12, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  29% 1.41G/4.88G [00:53<02:11, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  29% 1.42G/4.88G [00:54<02:10, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  29% 1.43G/4.88G [00:54<02:10, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  29% 1.44G/4.88G [00:54<02:09, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  30% 1.45G/4.88G [00:55<02:08, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  30% 1.46G/4.88G [00:55<02:08, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  30% 1.47G/4.88G [00:56<02:08, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  30% 1.48G/4.88G [00:56<02:07, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  31% 1.49G/4.88G [00:56<02:07, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  31% 1.50G/4.88G [00:57<02:07, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  31% 1.51G/4.88G [00:57<02:07, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  31% 1.52G/4.88G [00:58<02:07, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  31% 1.53G/4.88G [00:58<02:06, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  32% 1.54G/4.88G [00:58<02:05, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  32% 1.55G/4.88G [00:59<02:05, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  32% 1.56G/4.88G [00:59<02:05, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  32% 1.57G/4.88G [00:59<02:04, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  32% 1.58G/4.88G [01:00<02:04, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  33% 1.59G/4.88G [01:00<02:04, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  33% 1.60G/4.88G [01:01<02:03, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  33% 1.61G/4.88G [01:01<02:03, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  33% 1.63G/4.88G [01:01<02:03, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  34% 1.64G/4.88G [01:02<02:03, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  34% 1.65G/4.88G [01:02<02:02, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  34% 1.66G/4.88G [01:03<02:04, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  34% 1.67G/4.88G [01:03<02:05, 25.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  34% 1.68G/4.88G [01:04<02:05, 25.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  35% 1.69G/4.88G [01:04<02:03, 25.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  35% 1.70G/4.88G [01:04<02:02, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  35% 1.71G/4.88G [01:05<02:01, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  35% 1.72G/4.88G [01:05<02:00, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  35% 1.73G/4.88G [01:05<02:00, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  36% 1.74G/4.88G [01:06<01:58, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  36% 1.75G/4.88G [01:06<01:57, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  36% 1.76G/4.88G [01:07<01:57, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  36% 1.77G/4.88G [01:07<01:56, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  37% 1.78G/4.88G [01:07<01:56, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  37% 1.79G/4.88G [01:08<01:56, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  37% 1.80G/4.88G [01:08<01:55, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  37% 1.81G/4.88G [01:09<01:55, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  37% 1.82G/4.88G [01:09<01:54, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  38% 1.84G/4.88G [01:09<01:54, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  38% 1.85G/4.88G [01:10<01:54, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  38% 1.86G/4.88G [01:10<01:54, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  38% 1.87G/4.88G [01:11<01:53, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  38% 1.88G/4.88G [01:11<01:52, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  39% 1.89G/4.88G [01:11<01:52, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  39% 1.90G/4.88G [01:12<01:51, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  39% 1.91G/4.88G [01:12<01:51, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  39% 1.92G/4.88G [01:13<01:51, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  40% 1.93G/4.88G [01:13<01:50, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  40% 1.94G/4.88G [01:13<01:50, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  40% 1.95G/4.88G [01:14<01:50, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  40% 1.96G/4.88G [01:14<01:50, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  40% 1.97G/4.88G [01:15<01:50, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  41% 1.98G/4.88G [01:15<01:49, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  41% 1.99G/4.88G [01:15<01:49, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  41% 2.00G/4.88G [01:16<01:48, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  41% 2.01G/4.88G [01:16<01:48, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  41% 2.02G/4.88G [01:17<01:48, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  42% 2.03G/4.88G [01:17<01:50, 25.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  42% 2.04G/4.88G [01:17<01:49, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  42% 2.06G/4.88G [01:18<01:47, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  42% 2.07G/4.88G [01:18<01:48, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  43% 2.08G/4.88G [01:19<01:47, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  43% 2.09G/4.88G [01:19<01:46, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  43% 2.10G/4.88G [01:19<01:47, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  43% 2.11G/4.88G [01:20<01:46, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  43% 2.12G/4.88G [01:20<01:44, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  44% 2.13G/4.88G [01:21<01:44, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  44% 2.14G/4.88G [01:21<01:43, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  44% 2.15G/4.88G [01:21<01:42, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  44% 2.16G/4.88G [01:22<01:42, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  44% 2.17G/4.88G [01:22<01:42, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  45% 2.18G/4.88G [01:23<01:41, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  45% 2.19G/4.88G [01:23<01:41, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  45% 2.20G/4.88G [01:23<01:40, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  45% 2.21G/4.88G [01:24<01:40, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  46% 2.22G/4.88G [01:24<01:39, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  46% 2.23G/4.88G [01:25<01:39, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  46% 2.24G/4.88G [01:25<01:39, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  46% 2.25G/4.88G [01:25<01:38, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  46% 2.26G/4.88G [01:26<01:38, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  47% 2.28G/4.88G [01:26<01:38, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  47% 2.29G/4.88G [01:26<01:38, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  47% 2.30G/4.88G [01:27<01:37, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  47% 2.31G/4.88G [01:27<01:37, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  47% 2.32G/4.88G [01:28<01:36, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  48% 2.33G/4.88G [01:28<01:36, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  48% 2.34G/4.88G [01:28<01:35, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  48% 2.35G/4.88G [01:29<01:34, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  48% 2.36G/4.88G [01:29<01:34, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  49% 2.37G/4.88G [01:30<01:34, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  49% 2.38G/4.88G [01:30<01:34, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  49% 2.39G/4.88G [01:30<01:33, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  49% 2.40G/4.88G [01:31<01:33, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  49% 2.41G/4.88G [01:31<01:33, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  50% 2.42G/4.88G [01:32<01:32, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  50% 2.43G/4.88G [01:32<01:32, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  50% 2.44G/4.88G [01:32<01:31, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  50% 2.45G/4.88G [01:33<01:32, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  50% 2.46G/4.88G [01:33<01:32, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  51% 2.47G/4.88G [01:34<01:32, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  51% 2.49G/4.88G [01:34<01:31, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  51% 2.50G/4.88G [01:34<01:31, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  51% 2.51G/4.88G [01:35<01:30, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  52% 2.52G/4.88G [01:35<01:29, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  52% 2.53G/4.88G [01:36<01:29, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  52% 2.54G/4.88G [01:36<01:28, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  52% 2.55G/4.88G [01:36<01:28, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  52% 2.56G/4.88G [01:37<01:27, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  53% 2.57G/4.88G [01:37<01:27, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  53% 2.58G/4.88G [01:38<01:27, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  53% 2.59G/4.88G [01:38<01:27, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  53% 2.60G/4.88G [01:38<01:26, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  53% 2.61G/4.88G [01:39<01:26, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  54% 2.62G/4.88G [01:39<01:25, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  54% 2.63G/4.88G [01:40<01:25, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  54% 2.64G/4.88G [01:40<01:24, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  54% 2.65G/4.88G [01:40<01:24, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  55% 2.66G/4.88G [01:41<01:23, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  55% 2.67G/4.88G [01:41<01:23, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  55% 2.68G/4.88G [01:42<01:22, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  55% 2.69G/4.88G [01:42<01:22, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  55% 2.71G/4.88G [01:42<01:21, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  56% 2.72G/4.88G [01:43<01:21, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  56% 2.73G/4.88G [01:43<01:21, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  56% 2.74G/4.88G [01:44<01:20, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  56% 2.75G/4.88G [01:44<01:19, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  56% 2.76G/4.88G [01:44<01:19, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  57% 2.77G/4.88G [01:45<01:20, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  57% 2.78G/4.88G [01:45<01:19, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  57% 2.79G/4.88G [01:46<01:20, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  57% 2.80G/4.88G [01:46<01:19, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  58% 2.81G/4.88G [01:46<01:18, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  58% 2.82G/4.88G [01:47<01:18, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  58% 2.83G/4.88G [01:47<01:17, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  58% 2.84G/4.88G [01:48<01:17, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  58% 2.85G/4.88G [01:48<01:16, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  59% 2.86G/4.88G [01:48<01:16, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  59% 2.87G/4.88G [01:49<01:15, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  59% 2.88G/4.88G [01:49<01:15, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  59% 2.89G/4.88G [01:49<01:14, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  60% 2.90G/4.88G [01:50<01:14, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  60% 2.92G/4.88G [01:50<01:14, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  60% 2.93G/4.88G [01:51<01:14, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  60% 2.94G/4.88G [01:51<01:13, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  60% 2.95G/4.88G [01:51<01:13, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  61% 2.96G/4.88G [01:52<01:12, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  61% 2.97G/4.88G [01:52<01:12, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  61% 2.98G/4.88G [01:53<01:12, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  61% 2.99G/4.88G [01:53<01:12, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  61% 3.00G/4.88G [01:54<01:14, 25.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  62% 3.01G/4.88G [01:54<01:13, 25.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  62% 3.02G/4.88G [01:54<01:11, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  62% 3.03G/4.88G [01:55<01:11, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  62% 3.04G/4.88G [01:55<01:10, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  63% 3.05G/4.88G [01:55<01:09, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  63% 3.06G/4.88G [01:56<01:08, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  63% 3.07G/4.88G [01:56<01:08, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  63% 3.08G/4.88G [01:57<01:07, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  63% 3.09G/4.88G [01:57<01:07, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  64% 3.10G/4.88G [01:57<01:07, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  64% 3.11G/4.88G [01:58<01:06, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  64% 3.12G/4.88G [01:58<01:06, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  64% 3.14G/4.88G [01:59<01:05, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  64% 3.15G/4.88G [01:59<01:05, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  65% 3.16G/4.88G [01:59<01:05, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  65% 3.17G/4.88G [02:00<01:05, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  65% 3.18G/4.88G [02:00<01:05, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  65% 3.19G/4.88G [02:01<01:04, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  66% 3.20G/4.88G [02:01<01:04, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  66% 3.21G/4.88G [02:01<01:03, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  66% 3.22G/4.88G [02:02<01:03, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  66% 3.23G/4.88G [02:02<01:02, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  66% 3.24G/4.88G [02:03<01:02, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  67% 3.25G/4.88G [02:03<01:02, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  67% 3.26G/4.88G [02:03<01:02, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  67% 3.27G/4.88G [02:04<01:01, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  67% 3.28G/4.88G [02:04<01:01, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  67% 3.29G/4.88G [02:05<01:00, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  68% 3.30G/4.88G [02:05<01:00, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  68% 3.31G/4.88G [02:05<00:59, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  68% 3.32G/4.88G [02:06<00:59, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  68% 3.33G/4.88G [02:06<00:58, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  69% 3.34G/4.88G [02:07<00:58, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  69% 3.36G/4.88G [02:07<00:57, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  69% 3.37G/4.88G [02:07<00:57, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  69% 3.38G/4.88G [02:08<00:56, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  69% 3.39G/4.88G [02:08<00:56, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  70% 3.40G/4.88G [02:09<00:55, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  70% 3.41G/4.88G [02:09<00:55, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  70% 3.42G/4.88G [02:09<00:55, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  70% 3.43G/4.88G [02:10<00:54, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  70% 3.44G/4.88G [02:10<01:03, 22.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  71% 3.45G/4.88G [02:11<01:00, 23.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  71% 3.46G/4.88G [02:11<00:58, 24.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  71% 3.47G/4.88G [02:12<00:56, 24.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  71% 3.48G/4.88G [02:12<00:56, 24.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  72% 3.49G/4.88G [02:12<00:54, 25.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  72% 3.50G/4.88G [02:13<00:53, 25.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  72% 3.51G/4.88G [02:13<00:52, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  72% 3.52G/4.88G [02:14<00:51, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  72% 3.53G/4.88G [02:14<00:50, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  73% 3.54G/4.88G [02:14<00:50, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  73% 3.55G/4.88G [02:15<00:49, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  73% 3.57G/4.88G [02:15<00:49, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  73% 3.58G/4.88G [02:16<00:49, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  73% 3.59G/4.88G [02:16<00:50, 25.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  74% 3.60G/4.88G [02:16<00:49, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  74% 3.61G/4.88G [02:17<00:48, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  74% 3.62G/4.88G [02:17<00:48, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  74% 3.63G/4.88G [02:18<00:47, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  75% 3.64G/4.88G [02:18<00:46, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  75% 3.65G/4.88G [02:18<00:46, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  75% 3.66G/4.88G [02:19<00:45, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  75% 3.67G/4.88G [02:19<00:45, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  75% 3.68G/4.88G [02:20<00:45, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  76% 3.69G/4.88G [02:20<00:44, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  76% 3.70G/4.88G [02:20<00:44, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  76% 3.71G/4.88G [02:21<00:44, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  76% 3.72G/4.88G [02:21<00:44, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  76% 3.73G/4.88G [02:22<00:43, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  77% 3.74G/4.88G [02:22<00:43, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  77% 3.75G/4.88G [02:22<00:43, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  77% 3.76G/4.88G [02:23<00:42, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  77% 3.77G/4.88G [02:23<00:41, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  78% 3.79G/4.88G [02:24<00:41, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  78% 3.80G/4.88G [02:24<00:41, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  78% 3.81G/4.88G [02:24<00:40, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  78% 3.82G/4.88G [02:25<00:40, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  78% 3.83G/4.88G [02:25<00:40, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  79% 3.84G/4.88G [02:26<00:40, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  79% 3.85G/4.88G [02:26<00:39, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  79% 3.86G/4.88G [02:26<00:38, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  79% 3.87G/4.88G [02:27<00:38, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  79% 3.88G/4.88G [02:27<00:37, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  80% 3.89G/4.88G [02:28<00:37, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  80% 3.90G/4.88G [02:28<00:37, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  80% 3.91G/4.88G [02:28<00:36, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  80% 3.92G/4.88G [02:29<00:36, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  81% 3.93G/4.88G [02:29<00:35, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  81% 3.94G/4.88G [02:30<00:35, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  81% 3.95G/4.88G [02:30<00:34, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  81% 3.96G/4.88G [02:30<00:34, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  81% 3.97G/4.88G [02:31<00:33, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  82% 3.98G/4.88G [02:31<00:33, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  82% 4.00G/4.88G [02:31<00:33, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  82% 4.01G/4.88G [02:32<00:33, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  82% 4.02G/4.88G [02:32<00:32, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  82% 4.03G/4.88G [02:33<00:32, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  83% 4.04G/4.88G [02:33<00:31, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  83% 4.05G/4.88G [02:33<00:31, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  83% 4.06G/4.88G [02:34<00:31, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  83% 4.07G/4.88G [02:34<00:30, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  84% 4.08G/4.88G [02:35<00:30, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  84% 4.09G/4.88G [02:35<00:29, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  84% 4.10G/4.88G [02:35<00:29, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  84% 4.11G/4.88G [02:36<00:28, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  84% 4.12G/4.88G [02:36<00:28, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  85% 4.13G/4.88G [02:37<00:28, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  85% 4.14G/4.88G [02:37<00:29, 25.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  85% 4.15G/4.88G [02:37<00:27, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  85% 4.16G/4.88G [02:38<00:26, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  85% 4.17G/4.88G [02:38<00:26, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  86% 4.18G/4.88G [02:39<00:26, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  86% 4.19G/4.88G [02:39<00:25, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  86% 4.20G/4.88G [02:39<00:25, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  86% 4.22G/4.88G [02:40<00:25, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  87% 4.23G/4.88G [02:40<00:24, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  87% 4.24G/4.88G [02:41<00:24, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  87% 4.25G/4.88G [02:41<00:24, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  87% 4.26G/4.88G [02:41<00:23, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  87% 4.27G/4.88G [02:42<00:23, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  88% 4.28G/4.88G [02:42<00:22, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  88% 4.29G/4.88G [02:43<00:22, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  88% 4.30G/4.88G [02:43<00:21, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  88% 4.31G/4.88G [02:43<00:21, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  89% 4.32G/4.88G [02:44<00:21, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  89% 4.33G/4.88G [02:44<00:21, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  89% 4.34G/4.88G [02:45<00:20, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  89% 4.35G/4.88G [02:45<00:20, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  89% 4.36G/4.88G [02:45<00:19, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  90% 4.37G/4.88G [02:46<00:19, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  90% 4.38G/4.88G [02:46<00:18, 26.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  90% 4.39G/4.88G [02:47<00:18, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  90% 4.40G/4.88G [02:47<00:17, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  90% 4.41G/4.88G [02:47<00:17, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  91% 4.42G/4.88G [02:48<00:17, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  91% 4.44G/4.88G [02:48<00:16, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  91% 4.45G/4.88G [02:49<00:16, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  91% 4.46G/4.88G [02:49<00:15, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  92% 4.47G/4.88G [02:49<00:15, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  92% 4.48G/4.88G [02:50<00:15, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  92% 4.49G/4.88G [02:50<00:14, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  92% 4.50G/4.88G [02:50<00:14, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  92% 4.51G/4.88G [02:51<00:14, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  93% 4.52G/4.88G [02:51<00:13, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  93% 4.53G/4.88G [02:52<00:13, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  93% 4.54G/4.88G [02:52<00:12, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  93% 4.55G/4.88G [02:52<00:12, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  93% 4.56G/4.88G [02:53<00:12, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  94% 4.57G/4.88G [02:53<00:11, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  94% 4.58G/4.88G [02:54<00:11, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  94% 4.59G/4.88G [02:54<00:11, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  94% 4.60G/4.88G [02:54<00:10, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  95% 4.61G/4.88G [02:55<00:10, 26.0MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  95% 4.62G/4.88G [02:55<00:09, 25.9MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  95% 4.63G/4.88G [02:56<00:09, 26.1MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  95% 4.65G/4.88G [02:56<00:09, 26.2MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  95% 4.66G/4.88G [02:56<00:08, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  96% 4.67G/4.88G [02:57<00:08, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  96% 4.68G/4.88G [02:57<00:07, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  96% 4.69G/4.88G [02:58<00:07, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  96% 4.70G/4.88G [02:58<00:06, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  96% 4.71G/4.88G [02:58<00:06, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  97% 4.72G/4.88G [02:59<00:06, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  97% 4.73G/4.88G [02:59<00:05, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  97% 4.74G/4.88G [03:00<00:05, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  97% 4.75G/4.88G [03:00<00:04, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  98% 4.76G/4.88G [03:00<00:04, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  98% 4.77G/4.88G [03:01<00:04, 26.3MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  98% 4.78G/4.88G [03:01<00:03, 26.4MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  98% 4.79G/4.88G [03:02<00:03, 26.5MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  98% 4.80G/4.88G [03:02<00:02, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  99% 4.81G/4.88G [03:02<00:02, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  99% 4.82G/4.88G [03:03<00:02, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  99% 4.83G/4.88G [03:03<00:01, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  99% 4.84G/4.88G [03:04<00:01, 26.7MB/s]\u001b[A\n","model-00003-of-00006.safetensors:  99% 4.85G/4.88G [03:04<00:00, 26.6MB/s]\u001b[A\n","model-00003-of-00006.safetensors: 100% 4.87G/4.88G [03:04<00:00, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors: 100% 4.88G/4.88G [03:05<00:00, 26.8MB/s]\u001b[A\n","model-00003-of-00006.safetensors: 100% 4.88G/4.88G [03:05<00:00, 26.3MB/s]\n","Downloading shards:  50% 3/6 [05:45<06:25, 128.55s/it]\n","model-00004-of-00006.safetensors:   0% 0.00/4.93G [00:00<?, ?B/s]\u001b[A\n","model-00004-of-00006.safetensors:   0% 10.5M/4.93G [00:00<01:07, 73.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   0% 21.0M/4.93G [00:00<01:09, 71.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   1% 31.5M/4.93G [00:00<01:18, 62.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   1% 41.9M/4.93G [00:00<01:18, 62.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   1% 52.4M/4.93G [00:00<01:22, 59.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   1% 62.9M/4.93G [00:00<01:17, 62.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   1% 73.4M/4.93G [00:01<01:15, 64.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   2% 83.9M/4.93G [00:01<01:14, 65.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   2% 94.4M/4.93G [00:01<01:13, 65.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   2% 105M/4.93G [00:01<01:14, 64.5MB/s] \u001b[A\n","model-00004-of-00006.safetensors:   2% 115M/4.93G [00:01<01:15, 63.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   3% 126M/4.93G [00:01<01:11, 67.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   3% 136M/4.93G [00:02<01:10, 68.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   3% 147M/4.93G [00:02<01:07, 71.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   3% 157M/4.93G [00:02<01:08, 69.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   3% 168M/4.93G [00:02<01:09, 68.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   4% 178M/4.93G [00:02<01:10, 67.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   4% 189M/4.93G [00:02<01:15, 62.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   4% 199M/4.93G [00:03<01:12, 65.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   4% 210M/4.93G [00:03<01:09, 67.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   4% 220M/4.93G [00:03<01:08, 68.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   5% 231M/4.93G [00:03<01:12, 65.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   5% 241M/4.93G [00:03<01:08, 68.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   5% 252M/4.93G [00:03<01:07, 69.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   5% 262M/4.93G [00:03<01:10, 66.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   6% 273M/4.93G [00:04<01:15, 61.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   6% 283M/4.93G [00:04<01:14, 62.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   6% 294M/4.93G [00:04<01:12, 64.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   6% 304M/4.93G [00:04<01:10, 66.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   6% 315M/4.93G [00:04<01:07, 68.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   7% 325M/4.93G [00:04<01:05, 70.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   7% 336M/4.93G [00:05<01:04, 71.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   7% 346M/4.93G [00:05<01:05, 70.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   7% 357M/4.93G [00:05<01:03, 72.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   7% 367M/4.93G [00:05<01:04, 71.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   8% 377M/4.93G [00:05<01:09, 65.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   8% 388M/4.93G [00:05<01:08, 66.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   8% 398M/4.93G [00:05<01:09, 65.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   8% 409M/4.93G [00:06<01:07, 67.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   9% 419M/4.93G [00:06<01:07, 67.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   9% 430M/4.93G [00:06<01:07, 66.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   9% 440M/4.93G [00:06<01:28, 50.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   9% 451M/4.93G [00:06<01:24, 52.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:   9% 461M/4.93G [00:07<01:22, 54.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  10% 472M/4.93G [00:07<01:31, 48.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  10% 482M/4.93G [00:07<01:23, 53.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  10% 493M/4.93G [00:07<01:21, 54.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  10% 503M/4.93G [00:08<01:43, 42.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  10% 514M/4.93G [00:08<01:29, 49.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  11% 524M/4.93G [00:08<01:21, 53.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  11% 535M/4.93G [00:08<01:14, 59.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  11% 545M/4.93G [00:08<01:09, 63.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  11% 556M/4.93G [00:08<01:07, 64.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  11% 566M/4.93G [00:09<01:20, 54.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  12% 577M/4.93G [00:09<01:16, 56.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  12% 587M/4.93G [00:09<01:09, 62.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  12% 598M/4.93G [00:09<01:04, 66.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  12% 608M/4.93G [00:09<01:05, 66.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  13% 619M/4.93G [00:09<01:06, 64.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  13% 629M/4.93G [00:09<01:02, 68.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  13% 640M/4.93G [00:10<01:19, 54.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  13% 650M/4.93G [00:10<01:11, 60.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  13% 661M/4.93G [00:10<01:05, 64.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  14% 671M/4.93G [00:10<01:19, 53.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  14% 682M/4.93G [00:10<01:12, 58.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  14% 692M/4.93G [00:11<01:08, 62.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  14% 703M/4.93G [00:11<01:04, 65.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  14% 713M/4.93G [00:11<01:18, 54.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  15% 724M/4.93G [00:11<01:14, 56.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  15% 734M/4.93G [00:11<01:09, 60.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  15% 744M/4.93G [00:11<01:06, 63.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  15% 755M/4.93G [00:12<01:03, 66.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  16% 765M/4.93G [00:12<01:00, 68.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  16% 776M/4.93G [00:12<00:59, 70.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  16% 786M/4.93G [00:12<01:19, 52.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  16% 797M/4.93G [00:12<01:14, 55.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  16% 807M/4.93G [00:12<01:06, 62.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  17% 818M/4.93G [00:13<01:03, 64.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  17% 828M/4.93G [00:13<01:06, 61.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  17% 839M/4.93G [00:13<01:02, 65.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  17% 849M/4.93G [00:13<01:01, 66.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  17% 860M/4.93G [00:13<00:59, 68.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  18% 870M/4.93G [00:13<00:57, 70.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  18% 881M/4.93G [00:14<00:57, 70.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  18% 891M/4.93G [00:14<00:55, 72.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  18% 902M/4.93G [00:14<00:55, 72.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  18% 912M/4.93G [00:14<00:56, 71.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  19% 923M/4.93G [00:14<00:54, 73.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  19% 933M/4.93G [00:15<01:59, 33.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  19% 944M/4.93G [00:17<04:39, 14.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  20% 965M/4.93G [00:17<02:40, 24.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  20% 975M/4.93G [00:17<02:12, 30.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  20% 986M/4.93G [00:17<01:51, 35.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  20% 996M/4.93G [00:17<01:34, 41.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  20% 1.01G/4.93G [00:17<01:22, 47.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  21% 1.02G/4.93G [00:17<01:13, 53.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  21% 1.03G/4.93G [00:17<01:07, 57.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  21% 1.04G/4.93G [00:18<01:03, 61.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  21% 1.05G/4.93G [00:18<00:59, 65.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  21% 1.06G/4.93G [00:18<00:57, 67.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  22% 1.07G/4.93G [00:18<00:54, 70.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  22% 1.08G/4.93G [00:18<00:54, 70.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  22% 1.09G/4.93G [00:18<00:56, 68.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  22% 1.10G/4.93G [00:19<00:56, 68.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  23% 1.11G/4.93G [00:19<00:55, 69.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  23% 1.12G/4.93G [00:19<00:56, 67.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  23% 1.13G/4.93G [00:19<00:56, 66.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  23% 1.14G/4.93G [00:19<00:55, 67.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  23% 1.15G/4.93G [00:19<00:56, 67.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  24% 1.16G/4.93G [00:19<00:57, 66.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  24% 1.17G/4.93G [00:20<00:54, 69.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  24% 1.18G/4.93G [00:20<00:52, 71.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  24% 1.20G/4.93G [00:20<00:50, 74.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  24% 1.21G/4.93G [00:20<01:06, 56.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  25% 1.23G/4.93G [00:20<00:54, 67.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  25% 1.24G/4.93G [00:21<00:52, 71.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  25% 1.25G/4.93G [00:21<00:53, 68.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  26% 1.26G/4.93G [00:21<00:52, 70.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  26% 1.27G/4.93G [00:21<00:52, 69.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  26% 1.28G/4.93G [00:21<00:54, 67.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  26% 1.29G/4.93G [00:21<00:56, 64.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  26% 1.30G/4.93G [00:21<00:52, 68.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  27% 1.31G/4.93G [00:22<00:54, 66.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  27% 1.32G/4.93G [00:22<00:56, 64.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  27% 1.33G/4.93G [00:22<00:57, 63.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  27% 1.34G/4.93G [00:22<00:53, 66.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  27% 1.35G/4.93G [00:22<00:52, 68.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  28% 1.36G/4.93G [00:22<00:55, 64.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  28% 1.37G/4.93G [00:23<00:52, 68.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  28% 1.38G/4.93G [00:23<00:50, 69.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  28% 1.39G/4.93G [00:23<00:51, 68.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  28% 1.41G/4.93G [00:23<00:48, 72.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  29% 1.42G/4.93G [00:23<00:53, 66.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  29% 1.43G/4.93G [00:23<00:51, 67.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  29% 1.44G/4.93G [00:23<00:49, 70.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  29% 1.45G/4.93G [00:24<00:47, 73.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  30% 1.46G/4.93G [00:24<00:46, 74.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  30% 1.47G/4.93G [00:24<00:46, 74.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  30% 1.48G/4.93G [00:24<00:46, 74.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  30% 1.49G/4.93G [00:24<00:45, 75.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  30% 1.50G/4.93G [00:24<00:46, 74.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  31% 1.51G/4.93G [00:24<00:44, 76.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  31% 1.52G/4.93G [00:25<00:44, 77.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  31% 1.53G/4.93G [00:25<00:43, 78.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  31% 1.54G/4.93G [00:25<00:47, 71.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  31% 1.55G/4.93G [00:25<00:46, 73.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  32% 1.56G/4.93G [00:25<00:47, 71.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  32% 1.57G/4.93G [00:25<00:46, 71.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  32% 1.58G/4.93G [00:25<00:46, 71.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  32% 1.59G/4.93G [00:26<00:45, 74.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  33% 1.60G/4.93G [00:26<00:44, 75.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  33% 1.61G/4.93G [00:26<00:46, 71.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  33% 1.63G/4.93G [00:26<00:44, 74.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  33% 1.64G/4.93G [00:26<00:48, 67.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  33% 1.65G/4.93G [00:26<00:47, 69.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  34% 1.66G/4.93G [00:26<00:45, 72.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  34% 1.67G/4.93G [00:27<00:43, 74.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  34% 1.68G/4.93G [00:27<00:43, 74.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  34% 1.69G/4.93G [00:27<00:44, 73.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  34% 1.70G/4.93G [00:27<00:43, 75.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  35% 1.71G/4.93G [00:27<00:43, 73.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  35% 1.72G/4.93G [00:27<00:42, 75.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  35% 1.73G/4.93G [00:27<00:44, 72.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  35% 1.74G/4.93G [00:28<00:43, 74.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  35% 1.75G/4.93G [00:28<00:42, 75.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  36% 1.76G/4.93G [00:28<00:46, 68.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  36% 1.77G/4.93G [00:28<00:43, 72.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  36% 1.78G/4.93G [00:28<00:42, 74.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  36% 1.79G/4.93G [00:28<00:44, 70.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  37% 1.80G/4.93G [00:28<00:42, 73.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  37% 1.81G/4.93G [00:29<00:43, 71.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  37% 1.82G/4.93G [00:29<00:45, 68.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  37% 1.84G/4.93G [00:29<00:46, 67.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  37% 1.85G/4.93G [00:29<00:47, 65.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  38% 1.86G/4.93G [00:29<00:46, 65.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  38% 1.87G/4.93G [00:29<00:43, 70.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  38% 1.88G/4.93G [00:30<00:45, 67.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  38% 1.89G/4.93G [00:30<00:43, 70.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  38% 1.90G/4.93G [00:30<00:42, 72.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  39% 1.91G/4.93G [00:30<00:50, 60.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  39% 1.92G/4.93G [00:30<00:46, 65.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  39% 1.93G/4.93G [00:30<00:45, 65.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  39% 1.94G/4.93G [00:31<00:44, 67.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  40% 1.95G/4.93G [00:31<00:41, 71.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  40% 1.96G/4.93G [00:31<00:41, 72.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  40% 1.97G/4.93G [00:31<00:42, 70.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  40% 1.98G/4.93G [00:31<00:43, 67.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  40% 1.99G/4.93G [00:31<00:42, 69.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  41% 2.00G/4.93G [00:31<00:42, 69.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  41% 2.01G/4.93G [00:32<00:52, 55.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  41% 2.03G/4.93G [00:32<00:39, 73.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  41% 2.04G/4.93G [00:32<00:46, 62.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  42% 2.06G/4.93G [00:32<00:43, 65.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  42% 2.07G/4.93G [00:32<00:42, 68.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  42% 2.08G/4.93G [00:33<00:40, 71.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  42% 2.09G/4.93G [00:33<00:38, 73.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  43% 2.10G/4.93G [00:33<00:39, 71.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  43% 2.11G/4.93G [00:33<00:38, 73.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  43% 2.12G/4.93G [00:33<00:38, 73.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  43% 2.13G/4.93G [00:33<00:39, 70.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  43% 2.14G/4.93G [00:33<00:37, 74.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  44% 2.15G/4.93G [00:33<00:35, 77.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  44% 2.16G/4.93G [00:34<00:36, 75.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  44% 2.17G/4.93G [00:34<00:36, 76.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  44% 2.18G/4.93G [00:34<00:35, 76.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  44% 2.19G/4.93G [00:34<00:36, 75.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  45% 2.20G/4.93G [00:34<00:36, 75.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  45% 2.21G/4.93G [00:34<00:36, 74.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  45% 2.22G/4.93G [00:34<00:35, 76.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  45% 2.23G/4.93G [00:35<00:35, 75.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  45% 2.24G/4.93G [00:35<00:36, 73.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  46% 2.25G/4.93G [00:35<00:35, 75.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  46% 2.26G/4.93G [00:35<00:35, 74.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  46% 2.28G/4.93G [00:35<00:36, 73.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  46% 2.29G/4.93G [00:35<00:37, 71.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  47% 2.30G/4.93G [00:35<00:37, 70.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  47% 2.31G/4.93G [00:36<00:38, 67.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  47% 2.32G/4.93G [00:36<00:37, 70.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  47% 2.33G/4.93G [00:36<00:37, 69.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  47% 2.34G/4.93G [00:36<00:36, 71.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  48% 2.35G/4.93G [00:36<00:35, 72.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  48% 2.36G/4.93G [00:36<00:34, 73.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  48% 2.37G/4.93G [00:36<00:34, 74.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  48% 2.38G/4.93G [00:37<00:33, 75.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  48% 2.39G/4.93G [00:37<00:35, 71.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  49% 2.40G/4.93G [00:37<00:35, 71.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  49% 2.41G/4.93G [00:37<00:34, 73.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  49% 2.42G/4.93G [00:37<00:33, 75.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  49% 2.43G/4.93G [00:37<00:32, 77.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  50% 2.44G/4.93G [00:37<00:31, 78.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  50% 2.45G/4.93G [00:38<00:31, 78.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  50% 2.46G/4.93G [00:38<00:31, 78.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  50% 2.47G/4.93G [00:38<00:31, 77.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  50% 2.49G/4.93G [00:38<00:31, 78.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  51% 2.50G/4.93G [00:38<00:29, 81.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  51% 2.51G/4.93G [00:38<00:29, 82.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  51% 2.52G/4.93G [00:38<00:29, 81.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  51% 2.53G/4.93G [00:38<00:29, 81.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  51% 2.54G/4.93G [00:39<00:30, 77.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  52% 2.55G/4.93G [00:39<00:29, 80.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  52% 2.56G/4.93G [00:39<00:30, 77.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  52% 2.57G/4.93G [00:39<00:30, 76.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  52% 2.58G/4.93G [00:39<00:30, 78.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  52% 2.59G/4.93G [00:39<00:30, 75.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  53% 2.60G/4.93G [00:39<00:31, 74.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  53% 2.61G/4.93G [00:40<00:30, 75.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  53% 2.62G/4.93G [00:40<00:29, 77.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  53% 2.63G/4.93G [00:40<00:30, 75.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  54% 2.64G/4.93G [00:40<00:57, 40.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  54% 2.66G/4.93G [00:41<00:35, 63.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  54% 2.67G/4.93G [00:41<00:33, 67.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  54% 2.68G/4.93G [00:41<00:32, 69.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  55% 2.69G/4.93G [00:41<00:30, 72.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  55% 2.71G/4.93G [00:41<00:29, 74.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  55% 2.72G/4.93G [00:41<00:29, 75.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  55% 2.73G/4.93G [00:41<00:29, 75.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  55% 2.74G/4.93G [00:41<00:28, 77.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  56% 2.75G/4.93G [00:42<00:30, 72.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  56% 2.76G/4.93G [00:42<00:28, 75.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  56% 2.77G/4.93G [00:42<00:27, 77.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  56% 2.78G/4.93G [00:42<00:26, 80.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  57% 2.79G/4.93G [00:42<00:26, 81.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  57% 2.80G/4.93G [00:42<00:26, 79.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  57% 2.81G/4.93G [00:43<00:36, 57.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  57% 2.83G/4.93G [00:43<00:29, 72.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  58% 2.84G/4.93G [00:43<00:28, 74.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  58% 2.85G/4.93G [00:43<00:28, 71.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  58% 2.86G/4.93G [00:43<00:27, 76.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  58% 2.87G/4.93G [00:43<00:28, 73.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  58% 2.88G/4.93G [00:43<00:29, 70.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  59% 2.89G/4.93G [00:44<00:28, 70.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  59% 2.90G/4.93G [00:44<00:28, 71.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  59% 2.92G/4.93G [00:44<00:27, 74.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  59% 2.93G/4.93G [00:44<00:27, 74.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  60% 2.94G/4.93G [00:44<00:26, 75.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  60% 2.95G/4.93G [00:44<00:26, 76.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  60% 2.96G/4.93G [00:44<00:25, 78.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  60% 2.97G/4.93G [00:45<00:27, 71.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  60% 2.98G/4.93G [00:45<00:26, 73.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  61% 2.99G/4.93G [00:45<00:26, 73.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  61% 3.00G/4.93G [00:45<00:26, 72.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  61% 3.01G/4.93G [00:45<00:25, 74.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  61% 3.02G/4.93G [00:45<00:25, 74.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  61% 3.03G/4.93G [00:45<00:25, 73.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  62% 3.04G/4.93G [00:46<00:24, 77.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  62% 3.05G/4.93G [00:46<00:24, 76.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  62% 3.06G/4.93G [00:46<00:29, 64.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  62% 3.07G/4.93G [00:46<00:26, 69.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  62% 3.08G/4.93G [00:46<00:25, 71.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  63% 3.09G/4.93G [00:46<00:24, 75.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  63% 3.10G/4.93G [00:46<00:25, 72.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  63% 3.11G/4.93G [00:47<00:24, 73.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  63% 3.12G/4.93G [00:47<00:23, 76.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  64% 3.14G/4.93G [00:47<00:24, 74.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  64% 3.15G/4.93G [00:47<00:24, 73.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  64% 3.16G/4.93G [00:47<00:26, 68.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  64% 3.17G/4.93G [00:47<00:26, 67.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  64% 3.18G/4.93G [00:48<00:24, 71.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  65% 3.19G/4.93G [00:48<00:23, 73.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  65% 3.20G/4.93G [00:48<00:23, 73.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  65% 3.21G/4.93G [00:48<00:24, 71.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  65% 3.22G/4.93G [00:48<00:23, 74.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  65% 3.23G/4.93G [00:48<00:23, 73.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  66% 3.24G/4.93G [00:48<00:22, 75.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  66% 3.25G/4.93G [00:48<00:22, 75.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  66% 3.26G/4.93G [00:49<00:22, 74.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  66% 3.27G/4.93G [00:49<00:21, 76.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  67% 3.28G/4.93G [00:49<00:24, 68.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  67% 3.29G/4.93G [00:49<00:22, 72.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  67% 3.30G/4.93G [00:49<00:21, 75.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  67% 3.31G/4.93G [00:49<00:22, 73.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  67% 3.32G/4.93G [00:49<00:21, 75.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  68% 3.33G/4.93G [00:50<00:21, 75.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  68% 3.34G/4.93G [00:50<00:20, 76.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  68% 3.36G/4.93G [00:51<00:54, 28.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  68% 3.38G/4.93G [00:51<00:33, 46.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  69% 3.39G/4.93G [00:51<00:32, 48.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  69% 3.40G/4.93G [00:51<00:28, 54.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  69% 3.41G/4.93G [00:51<00:26, 57.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  69% 3.42G/4.93G [00:51<00:24, 62.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  69% 3.43G/4.93G [00:52<00:24, 61.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  70% 3.44G/4.93G [00:52<00:23, 63.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  70% 3.45G/4.93G [00:52<00:22, 66.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  70% 3.46G/4.93G [00:52<00:21, 70.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  70% 3.47G/4.93G [00:52<00:20, 72.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  71% 3.48G/4.93G [00:52<00:20, 72.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  71% 3.49G/4.93G [00:52<00:20, 70.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  71% 3.50G/4.93G [00:53<00:19, 73.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  71% 3.51G/4.93G [00:53<00:19, 71.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  71% 3.52G/4.93G [00:53<00:19, 71.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  72% 3.53G/4.93G [00:53<00:19, 73.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  72% 3.54G/4.93G [00:53<00:18, 75.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  72% 3.55G/4.93G [00:53<00:17, 76.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  72% 3.57G/4.93G [00:53<00:17, 78.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  72% 3.58G/4.93G [00:54<00:17, 78.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  73% 3.59G/4.93G [00:54<00:16, 79.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  73% 3.60G/4.93G [00:54<00:16, 79.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  73% 3.61G/4.93G [00:54<00:16, 80.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  73% 3.62G/4.93G [00:54<00:17, 76.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  74% 3.63G/4.93G [00:54<00:16, 78.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  74% 3.64G/4.93G [00:54<00:16, 78.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  74% 3.65G/4.93G [00:54<00:16, 79.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  74% 3.66G/4.93G [00:55<00:16, 78.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  74% 3.67G/4.93G [00:55<00:17, 73.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  75% 3.68G/4.93G [00:55<00:17, 73.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  75% 3.69G/4.93G [00:55<00:16, 74.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  75% 3.70G/4.93G [00:55<00:15, 77.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  75% 3.71G/4.93G [00:55<00:16, 76.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  75% 3.72G/4.93G [00:55<00:17, 70.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  76% 3.73G/4.93G [00:56<00:16, 73.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  76% 3.74G/4.93G [00:56<00:17, 68.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  76% 3.75G/4.93G [00:56<00:17, 68.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  76% 3.76G/4.93G [00:56<00:16, 69.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  77% 3.77G/4.93G [00:56<00:16, 68.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  77% 3.79G/4.93G [00:56<00:17, 64.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  77% 3.80G/4.93G [00:57<00:21, 53.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  77% 3.81G/4.93G [00:57<00:20, 55.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  77% 3.82G/4.93G [00:57<00:19, 57.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  78% 3.83G/4.93G [00:57<00:19, 56.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  78% 3.84G/4.93G [00:57<00:17, 61.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  78% 3.85G/4.93G [00:58<00:17, 61.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  78% 3.86G/4.93G [00:58<00:16, 64.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  78% 3.87G/4.93G [00:58<00:16, 64.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  79% 3.88G/4.93G [00:58<00:16, 64.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  79% 3.89G/4.93G [00:58<00:15, 69.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  79% 3.90G/4.93G [00:58<00:14, 70.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  79% 3.91G/4.93G [00:58<00:14, 70.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  79% 3.92G/4.93G [00:59<00:14, 71.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  80% 3.93G/4.93G [00:59<00:13, 71.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  80% 3.94G/4.93G [00:59<00:13, 72.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  80% 3.95G/4.93G [00:59<00:13, 72.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  80% 3.96G/4.93G [00:59<00:13, 72.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  81% 3.97G/4.93G [00:59<00:13, 69.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  81% 3.98G/4.93G [00:59<00:13, 70.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  81% 4.00G/4.93G [01:00<00:12, 72.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  81% 4.01G/4.93G [01:00<00:12, 75.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  81% 4.02G/4.93G [01:00<00:12, 73.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  82% 4.03G/4.93G [01:00<00:12, 72.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  82% 4.04G/4.93G [01:00<00:12, 71.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  82% 4.05G/4.93G [01:00<00:12, 72.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  82% 4.06G/4.93G [01:00<00:11, 73.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  82% 4.07G/4.93G [01:01<00:11, 73.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  83% 4.08G/4.93G [01:01<00:11, 75.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  83% 4.09G/4.93G [01:01<00:11, 75.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  83% 4.10G/4.93G [01:01<00:12, 67.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  83% 4.11G/4.93G [01:01<00:12, 64.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  84% 4.12G/4.93G [01:01<00:13, 61.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  84% 4.13G/4.93G [01:02<00:12, 66.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  84% 4.14G/4.93G [01:02<00:11, 69.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  84% 4.15G/4.93G [01:02<00:11, 69.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  84% 4.16G/4.93G [01:02<00:10, 70.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  85% 4.17G/4.93G [01:02<00:10, 71.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  85% 4.18G/4.93G [01:02<00:10, 73.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  85% 4.19G/4.93G [01:02<00:10, 69.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  85% 4.20G/4.93G [01:03<00:12, 57.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  86% 4.23G/4.93G [01:03<00:10, 70.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  86% 4.24G/4.93G [01:03<00:09, 70.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  86% 4.25G/4.93G [01:03<00:10, 63.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  86% 4.26G/4.93G [01:03<00:10, 64.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  87% 4.27G/4.93G [01:04<00:09, 67.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  87% 4.28G/4.93G [01:04<00:09, 69.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  87% 4.29G/4.93G [01:04<00:09, 71.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  87% 4.30G/4.93G [01:04<00:08, 73.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  87% 4.31G/4.93G [01:04<00:08, 75.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  88% 4.32G/4.93G [01:04<00:08, 74.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  88% 4.33G/4.93G [01:04<00:08, 69.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  88% 4.34G/4.93G [01:05<00:08, 67.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  88% 4.35G/4.93G [01:05<00:08, 68.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  88% 4.36G/4.93G [01:05<00:07, 73.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  89% 4.37G/4.93G [01:05<00:07, 74.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  89% 4.38G/4.93G [01:05<00:07, 75.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  89% 4.39G/4.93G [01:05<00:08, 65.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  89% 4.40G/4.93G [01:05<00:08, 64.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  89% 4.41G/4.93G [01:06<00:07, 69.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  90% 4.42G/4.93G [01:06<00:07, 71.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  90% 4.44G/4.93G [01:06<00:06, 71.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  90% 4.45G/4.93G [01:06<00:06, 73.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  90% 4.46G/4.93G [01:06<00:06, 74.6MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  91% 4.47G/4.93G [01:06<00:06, 72.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  91% 4.48G/4.93G [01:06<00:06, 68.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  91% 4.49G/4.93G [01:07<00:06, 70.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  91% 4.50G/4.93G [01:07<00:05, 73.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  91% 4.51G/4.93G [01:07<00:06, 70.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  92% 4.52G/4.93G [01:07<00:05, 72.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  92% 4.53G/4.93G [01:07<00:05, 70.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  92% 4.54G/4.93G [01:07<00:05, 69.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  92% 4.55G/4.93G [01:08<00:05, 68.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  92% 4.56G/4.93G [01:08<00:05, 70.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  93% 4.57G/4.93G [01:08<00:05, 70.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  93% 4.58G/4.93G [01:08<00:05, 70.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  93% 4.59G/4.93G [01:08<00:04, 73.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  93% 4.60G/4.93G [01:08<00:04, 72.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  94% 4.61G/4.93G [01:08<00:04, 74.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  94% 4.62G/4.93G [01:08<00:04, 76.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  94% 4.63G/4.93G [01:09<00:03, 78.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  94% 4.65G/4.93G [01:09<00:03, 74.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  94% 4.66G/4.93G [01:09<00:03, 70.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  95% 4.67G/4.93G [01:09<00:03, 72.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  95% 4.68G/4.93G [01:09<00:03, 74.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  95% 4.69G/4.93G [01:09<00:03, 71.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  95% 4.70G/4.93G [01:10<00:03, 73.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  95% 4.71G/4.93G [01:10<00:03, 72.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  96% 4.72G/4.93G [01:10<00:03, 71.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  96% 4.73G/4.93G [01:10<00:02, 72.0MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  96% 4.74G/4.93G [01:10<00:02, 69.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  96% 4.75G/4.93G [01:10<00:03, 58.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  96% 4.76G/4.93G [01:11<00:03, 56.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  97% 4.77G/4.93G [01:11<00:02, 61.8MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  97% 4.78G/4.93G [01:11<00:02, 66.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  97% 4.79G/4.93G [01:11<00:02, 65.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  97% 4.80G/4.93G [01:11<00:02, 61.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  98% 4.81G/4.93G [01:11<00:01, 63.7MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  98% 4.82G/4.93G [01:11<00:01, 68.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  98% 4.83G/4.93G [01:12<00:01, 70.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  98% 4.84G/4.93G [01:12<00:01, 72.5MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  98% 4.85G/4.93G [01:12<00:01, 68.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  99% 4.87G/4.93G [01:12<00:01, 66.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  99% 4.88G/4.93G [01:12<00:00, 71.3MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  99% 4.89G/4.93G [01:12<00:00, 67.4MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  99% 4.90G/4.93G [01:13<00:00, 69.1MB/s]\u001b[A\n","model-00004-of-00006.safetensors:  99% 4.91G/4.93G [01:13<00:00, 71.2MB/s]\u001b[A\n","model-00004-of-00006.safetensors: 100% 4.92G/4.93G [01:13<00:00, 72.9MB/s]\u001b[A\n","model-00004-of-00006.safetensors: 100% 4.93G/4.93G [01:13<00:00, 67.1MB/s]\n","Downloading shards:  67% 4/6 [06:59<03:34, 107.01s/it]\n","model-00005-of-00006.safetensors:   0% 0.00/4.93G [00:00<?, ?B/s]\u001b[A\n","model-00005-of-00006.safetensors:   0% 10.5M/4.93G [00:00<00:58, 84.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   0% 21.0M/4.93G [00:00<00:57, 85.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   1% 31.5M/4.93G [00:00<01:01, 79.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   1% 41.9M/4.93G [00:00<01:01, 79.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   1% 52.4M/4.93G [00:00<01:02, 78.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   1% 62.9M/4.93G [00:00<01:05, 74.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   1% 73.4M/4.93G [00:00<01:03, 76.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   2% 83.9M/4.93G [00:01<01:05, 73.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   2% 94.4M/4.93G [00:01<01:03, 76.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   2% 105M/4.93G [00:01<01:29, 54.2MB/s] \u001b[A\n","model-00005-of-00006.safetensors:   3% 126M/4.93G [00:01<01:02, 77.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   3% 136M/4.93G [00:01<01:02, 77.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   3% 147M/4.93G [00:01<01:01, 77.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   3% 157M/4.93G [00:02<01:00, 78.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   3% 168M/4.93G [00:02<01:01, 77.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   4% 178M/4.93G [00:02<01:00, 78.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   4% 189M/4.93G [00:02<00:59, 79.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   4% 199M/4.93G [00:02<00:59, 79.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   4% 210M/4.93G [00:02<01:01, 77.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   4% 220M/4.93G [00:02<01:02, 75.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   5% 231M/4.93G [00:03<01:02, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   5% 241M/4.93G [00:03<01:00, 77.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   5% 252M/4.93G [00:03<01:00, 77.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   5% 262M/4.93G [00:03<01:00, 76.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   6% 273M/4.93G [00:03<01:00, 76.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   6% 283M/4.93G [00:03<00:58, 78.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   6% 294M/4.93G [00:03<00:59, 78.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   6% 304M/4.93G [00:03<00:57, 80.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   6% 315M/4.93G [00:04<00:59, 77.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   7% 325M/4.93G [00:04<00:58, 78.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   7% 336M/4.93G [00:04<00:58, 78.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   7% 346M/4.93G [00:04<00:59, 77.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   7% 357M/4.93G [00:04<00:59, 76.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   7% 367M/4.93G [00:04<00:58, 78.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   8% 377M/4.93G [00:04<00:56, 80.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   8% 388M/4.93G [00:05<00:58, 78.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   8% 398M/4.93G [00:05<00:56, 80.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   8% 409M/4.93G [00:05<00:55, 81.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   9% 419M/4.93G [00:05<00:56, 80.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   9% 430M/4.93G [00:05<00:58, 77.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   9% 440M/4.93G [00:05<00:57, 77.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   9% 451M/4.93G [00:05<00:58, 76.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:   9% 461M/4.93G [00:05<01:00, 74.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  10% 472M/4.93G [00:06<01:00, 74.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  10% 482M/4.93G [00:06<00:59, 74.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  10% 493M/4.93G [00:06<00:58, 75.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  10% 503M/4.93G [00:06<00:59, 75.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  10% 514M/4.93G [00:06<01:06, 66.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  11% 524M/4.93G [00:06<01:02, 70.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  11% 535M/4.93G [00:07<01:00, 72.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  11% 545M/4.93G [00:07<00:58, 75.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  11% 556M/4.93G [00:07<00:57, 76.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  11% 566M/4.93G [00:07<00:55, 78.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  12% 577M/4.93G [00:07<00:54, 79.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  12% 587M/4.93G [00:07<00:55, 78.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  12% 598M/4.93G [00:07<00:54, 79.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  12% 608M/4.93G [00:07<00:53, 80.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  13% 619M/4.93G [00:08<00:54, 79.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  13% 629M/4.93G [00:08<00:54, 78.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  13% 640M/4.93G [00:08<00:56, 76.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  13% 650M/4.93G [00:08<00:55, 76.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  13% 661M/4.93G [00:08<00:56, 75.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  14% 671M/4.93G [00:08<00:57, 74.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  14% 682M/4.93G [00:08<00:56, 74.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  14% 692M/4.93G [00:09<00:58, 72.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  14% 703M/4.93G [00:09<00:56, 75.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  14% 713M/4.93G [00:09<00:55, 76.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  15% 724M/4.93G [00:09<00:57, 73.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  15% 734M/4.93G [00:09<00:56, 74.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  15% 744M/4.93G [00:09<00:55, 75.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  15% 755M/4.93G [00:09<00:56, 74.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  16% 765M/4.93G [00:10<00:54, 76.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  16% 776M/4.93G [00:10<00:53, 78.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  16% 786M/4.93G [00:10<00:52, 78.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  16% 797M/4.93G [00:10<00:53, 77.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  16% 807M/4.93G [00:10<00:52, 78.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  17% 818M/4.93G [00:10<00:54, 75.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  17% 828M/4.93G [00:10<00:53, 76.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  17% 839M/4.93G [00:10<00:53, 75.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  17% 849M/4.93G [00:11<00:53, 77.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  17% 860M/4.93G [00:11<00:52, 78.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  18% 870M/4.93G [00:11<00:51, 79.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  18% 881M/4.93G [00:11<00:51, 79.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  18% 891M/4.93G [00:11<00:51, 78.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  18% 902M/4.93G [00:11<00:54, 73.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  18% 912M/4.93G [00:11<01:01, 65.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  19% 923M/4.93G [00:12<00:57, 69.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  19% 933M/4.93G [00:12<01:07, 59.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  19% 954M/4.93G [00:12<00:54, 73.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  20% 965M/4.93G [00:12<00:52, 75.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  20% 975M/4.93G [00:12<00:53, 74.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  20% 986M/4.93G [00:12<00:52, 75.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  20% 996M/4.93G [00:13<00:54, 71.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  20% 1.01G/4.93G [00:13<00:57, 68.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  21% 1.02G/4.93G [00:13<00:54, 71.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  21% 1.03G/4.93G [00:13<00:53, 72.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  21% 1.04G/4.93G [00:13<00:53, 72.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  21% 1.05G/4.93G [00:13<00:53, 72.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  21% 1.06G/4.93G [00:14<00:53, 72.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  22% 1.07G/4.93G [00:14<00:53, 71.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  22% 1.08G/4.93G [00:14<00:51, 74.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  22% 1.09G/4.93G [00:14<00:50, 75.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  22% 1.10G/4.93G [00:14<00:50, 75.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  23% 1.11G/4.93G [00:14<00:50, 76.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  23% 1.12G/4.93G [00:14<00:49, 76.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  23% 1.13G/4.93G [00:14<00:49, 77.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  23% 1.14G/4.93G [00:15<00:48, 78.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  23% 1.15G/4.93G [00:15<00:48, 78.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  24% 1.16G/4.93G [00:15<00:47, 78.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  24% 1.17G/4.93G [00:15<00:49, 76.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  24% 1.18G/4.93G [00:15<00:49, 76.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  24% 1.20G/4.93G [00:15<00:50, 74.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  24% 1.21G/4.93G [00:15<00:52, 71.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  25% 1.22G/4.93G [00:16<00:49, 74.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  25% 1.23G/4.93G [00:16<00:48, 76.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  25% 1.24G/4.93G [00:16<00:52, 70.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  25% 1.25G/4.93G [00:16<00:50, 73.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  26% 1.26G/4.93G [00:16<00:55, 66.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  26% 1.27G/4.93G [00:16<00:51, 70.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  26% 1.28G/4.93G [00:17<00:54, 67.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  26% 1.29G/4.93G [00:17<00:51, 70.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  26% 1.30G/4.93G [00:17<00:50, 72.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  27% 1.31G/4.93G [00:17<00:49, 72.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  27% 1.32G/4.93G [00:17<00:49, 73.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  27% 1.33G/4.93G [00:17<00:47, 75.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  27% 1.34G/4.93G [00:17<00:50, 70.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  27% 1.35G/4.93G [00:18<00:50, 70.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  28% 1.36G/4.93G [00:18<00:50, 71.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  28% 1.37G/4.93G [00:18<00:47, 74.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  28% 1.38G/4.93G [00:18<00:46, 75.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  28% 1.39G/4.93G [00:18<00:45, 77.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  28% 1.41G/4.93G [00:18<00:47, 74.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  29% 1.42G/4.93G [00:18<00:46, 75.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  29% 1.43G/4.93G [00:18<00:48, 73.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  29% 1.44G/4.93G [00:19<00:45, 76.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  29% 1.45G/4.93G [00:19<00:44, 77.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  30% 1.46G/4.93G [00:19<00:44, 78.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  30% 1.47G/4.93G [00:19<00:44, 77.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  30% 1.48G/4.93G [00:19<00:45, 76.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  30% 1.49G/4.93G [00:19<00:44, 77.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  30% 1.50G/4.93G [00:19<00:46, 74.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  31% 1.51G/4.93G [00:20<00:46, 73.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  31% 1.52G/4.93G [00:20<00:45, 75.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  31% 1.53G/4.93G [00:20<00:43, 77.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  31% 1.54G/4.93G [00:20<00:44, 76.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  31% 1.55G/4.93G [00:20<00:43, 77.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  32% 1.56G/4.93G [00:20<00:44, 75.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  32% 1.57G/4.93G [00:20<00:44, 75.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  32% 1.58G/4.93G [00:21<00:45, 73.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  32% 1.59G/4.93G [00:21<00:44, 74.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  33% 1.60G/4.93G [00:21<00:43, 76.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  33% 1.61G/4.93G [00:21<00:42, 77.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  33% 1.63G/4.93G [00:21<00:43, 75.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  33% 1.64G/4.93G [00:21<00:43, 75.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  33% 1.65G/4.93G [00:21<00:44, 74.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  34% 1.66G/4.93G [00:22<00:45, 72.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  34% 1.67G/4.93G [00:22<00:46, 70.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  34% 1.68G/4.93G [00:22<00:45, 72.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  34% 1.69G/4.93G [00:22<00:44, 72.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  34% 1.70G/4.93G [00:22<00:43, 74.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  35% 1.71G/4.93G [00:22<00:42, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  35% 1.72G/4.93G [00:22<00:40, 78.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  35% 1.73G/4.93G [00:23<00:42, 76.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  35% 1.74G/4.93G [00:23<00:40, 78.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  35% 1.75G/4.93G [00:23<00:40, 78.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  36% 1.76G/4.93G [00:23<00:39, 80.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  36% 1.77G/4.93G [00:23<00:39, 80.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  36% 1.78G/4.93G [00:23<00:53, 59.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  37% 1.80G/4.93G [00:23<00:37, 84.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  37% 1.81G/4.93G [00:24<00:37, 82.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  37% 1.82G/4.93G [00:24<00:39, 79.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  37% 1.84G/4.93G [00:24<00:39, 78.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  37% 1.85G/4.93G [00:24<00:39, 78.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  38% 1.86G/4.93G [00:24<00:38, 79.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  38% 1.87G/4.93G [00:24<00:39, 77.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  38% 1.88G/4.93G [00:24<00:38, 78.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  38% 1.89G/4.93G [00:25<00:40, 75.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  38% 1.90G/4.93G [00:25<00:40, 74.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  39% 1.91G/4.93G [00:25<00:40, 74.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  39% 1.92G/4.93G [00:25<00:40, 74.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  39% 1.93G/4.93G [00:25<00:39, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  39% 1.94G/4.93G [00:25<00:39, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  40% 1.95G/4.93G [00:25<00:39, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  40% 1.96G/4.93G [00:26<00:38, 77.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  40% 1.97G/4.93G [00:29<04:47, 10.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  40% 1.99G/4.93G [00:29<02:41, 18.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  41% 2.00G/4.93G [00:29<02:09, 22.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  41% 2.01G/4.93G [00:29<01:44, 28.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  41% 2.02G/4.93G [00:29<01:25, 33.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  41% 2.03G/4.93G [00:29<01:12, 40.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  41% 2.04G/4.93G [00:29<01:03, 45.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  42% 2.06G/4.93G [00:30<00:57, 50.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  42% 2.07G/4.93G [00:30<00:56, 50.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  42% 2.08G/4.93G [00:30<00:51, 55.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  42% 2.09G/4.93G [00:30<00:47, 60.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  43% 2.10G/4.93G [00:30<00:47, 60.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  43% 2.11G/4.93G [00:30<00:43, 65.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  43% 2.12G/4.93G [00:30<00:41, 67.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  43% 2.13G/4.93G [00:31<00:39, 71.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  43% 2.14G/4.93G [00:31<00:37, 74.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  44% 2.15G/4.93G [00:31<00:37, 75.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  44% 2.16G/4.93G [00:31<00:35, 77.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  44% 2.17G/4.93G [00:31<00:36, 75.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  44% 2.18G/4.93G [00:31<00:36, 74.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  44% 2.19G/4.93G [00:31<00:40, 68.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  45% 2.20G/4.93G [00:32<00:37, 72.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  45% 2.21G/4.93G [00:32<00:36, 74.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  45% 2.22G/4.93G [00:32<00:34, 78.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  45% 2.23G/4.93G [00:32<00:33, 80.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  45% 2.24G/4.93G [00:32<00:34, 77.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  46% 2.25G/4.93G [00:32<00:34, 78.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  46% 2.26G/4.93G [00:32<00:34, 77.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  46% 2.28G/4.93G [00:32<00:33, 78.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  46% 2.29G/4.93G [00:33<00:33, 79.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  47% 2.30G/4.93G [00:33<00:33, 78.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  47% 2.31G/4.93G [00:33<00:34, 77.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  47% 2.32G/4.93G [00:33<00:33, 77.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  47% 2.33G/4.93G [00:33<00:34, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  47% 2.34G/4.93G [00:33<00:34, 75.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  48% 2.35G/4.93G [00:33<00:35, 72.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  48% 2.36G/4.93G [00:34<00:34, 74.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  48% 2.37G/4.93G [00:34<00:34, 74.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  48% 2.38G/4.93G [00:34<00:33, 75.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  48% 2.39G/4.93G [00:34<00:32, 77.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  49% 2.40G/4.93G [00:34<00:34, 72.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  49% 2.41G/4.93G [00:34<00:33, 74.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  49% 2.42G/4.93G [00:34<00:33, 74.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  49% 2.43G/4.93G [00:35<00:33, 74.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  50% 2.44G/4.93G [00:35<00:32, 76.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  50% 2.45G/4.93G [00:35<00:32, 76.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  50% 2.46G/4.93G [00:35<00:31, 78.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  50% 2.47G/4.93G [00:35<00:42, 58.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  51% 2.50G/4.93G [00:35<00:32, 75.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  51% 2.51G/4.93G [00:36<00:31, 76.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  51% 2.52G/4.93G [00:36<00:31, 76.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  51% 2.53G/4.93G [00:36<00:30, 78.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  51% 2.54G/4.93G [00:36<00:31, 75.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  52% 2.55G/4.93G [00:36<00:32, 74.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  52% 2.56G/4.93G [00:36<00:32, 73.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  52% 2.57G/4.93G [00:36<00:31, 76.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  52% 2.58G/4.93G [00:37<00:30, 77.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  52% 2.59G/4.93G [00:39<02:51, 13.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  53% 2.61G/4.93G [00:39<01:38, 23.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  53% 2.62G/4.93G [00:39<01:20, 28.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  53% 2.63G/4.93G [00:39<01:08, 33.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  54% 2.64G/4.93G [00:39<00:59, 38.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  54% 2.65G/4.93G [00:40<00:52, 43.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  54% 2.66G/4.93G [00:40<00:45, 49.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  54% 2.67G/4.93G [00:40<00:48, 46.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  54% 2.68G/4.93G [00:40<00:42, 53.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  55% 2.69G/4.93G [00:40<00:38, 58.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  55% 2.71G/4.93G [00:40<00:36, 61.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  55% 2.72G/4.93G [00:41<00:35, 63.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  55% 2.73G/4.93G [00:41<00:33, 66.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  55% 2.74G/4.93G [00:41<00:31, 68.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  56% 2.75G/4.93G [00:41<00:31, 70.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  56% 2.76G/4.93G [00:41<00:30, 72.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  56% 2.77G/4.93G [00:41<00:29, 73.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  56% 2.78G/4.93G [00:41<00:29, 73.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  57% 2.79G/4.93G [00:42<00:30, 70.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  57% 2.80G/4.93G [00:42<00:29, 72.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  57% 2.81G/4.93G [00:42<00:29, 71.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  57% 2.82G/4.93G [00:42<00:29, 72.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  57% 2.83G/4.93G [00:42<00:29, 71.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  58% 2.84G/4.93G [00:42<00:30, 69.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  58% 2.85G/4.93G [00:42<00:28, 73.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  58% 2.86G/4.93G [00:43<00:41, 49.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  58% 2.87G/4.93G [00:43<00:42, 48.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  58% 2.88G/4.93G [00:43<00:37, 54.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  59% 2.89G/4.93G [00:43<00:34, 58.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  59% 2.90G/4.93G [00:43<00:32, 62.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  59% 2.92G/4.93G [00:44<00:30, 66.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  59% 2.93G/4.93G [00:44<00:29, 67.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  60% 2.94G/4.93G [00:44<00:36, 54.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  60% 2.95G/4.93G [00:44<00:33, 60.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  60% 2.96G/4.93G [00:44<00:31, 61.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  60% 2.97G/4.93G [00:44<00:30, 64.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  60% 2.98G/4.93G [00:45<00:30, 63.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  61% 2.99G/4.93G [00:45<00:30, 64.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  61% 3.00G/4.93G [00:45<00:29, 66.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  61% 3.01G/4.93G [00:45<00:27, 69.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  61% 3.02G/4.93G [00:45<00:26, 71.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  61% 3.03G/4.93G [00:45<00:26, 70.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  62% 3.04G/4.93G [00:45<00:26, 71.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  62% 3.05G/4.93G [00:46<00:27, 67.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  62% 3.06G/4.93G [00:46<00:27, 67.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  62% 3.07G/4.93G [00:46<00:27, 67.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  62% 3.08G/4.93G [00:46<00:27, 68.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  63% 3.09G/4.93G [00:46<00:26, 69.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  63% 3.10G/4.93G [00:46<00:25, 70.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  63% 3.11G/4.93G [00:47<00:26, 67.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  63% 3.12G/4.93G [00:47<00:26, 69.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  64% 3.14G/4.93G [00:47<00:26, 67.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  64% 3.15G/4.93G [00:47<00:25, 69.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  64% 3.16G/4.93G [00:47<00:25, 68.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  64% 3.17G/4.93G [00:47<00:27, 64.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  64% 3.18G/4.93G [00:47<00:25, 68.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  65% 3.19G/4.93G [00:48<00:25, 67.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  65% 3.20G/4.93G [00:48<00:25, 69.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  65% 3.21G/4.93G [00:48<00:24, 70.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  65% 3.22G/4.93G [00:48<00:23, 73.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  65% 3.23G/4.93G [00:48<00:23, 73.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  66% 3.24G/4.93G [00:48<00:22, 75.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  66% 3.25G/4.93G [00:48<00:22, 76.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  66% 3.26G/4.93G [00:49<00:21, 76.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  66% 3.27G/4.93G [00:49<00:21, 78.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  67% 3.28G/4.93G [00:49<00:22, 74.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  67% 3.29G/4.93G [00:49<00:21, 75.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  67% 3.30G/4.93G [00:49<00:23, 70.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  67% 3.31G/4.93G [00:49<00:24, 66.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  67% 3.32G/4.93G [00:50<00:26, 60.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  68% 3.33G/4.93G [00:50<00:24, 64.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  68% 3.34G/4.93G [00:50<00:23, 67.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  68% 3.36G/4.93G [00:50<00:22, 69.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  68% 3.37G/4.93G [00:50<00:21, 72.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  68% 3.38G/4.93G [00:50<00:20, 74.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  69% 3.39G/4.93G [00:50<00:20, 74.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  69% 3.40G/4.93G [00:51<00:21, 72.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  69% 3.41G/4.93G [00:51<00:20, 73.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  69% 3.42G/4.93G [00:51<00:21, 69.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  69% 3.43G/4.93G [00:51<00:20, 73.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  70% 3.44G/4.93G [00:51<00:21, 70.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  70% 3.45G/4.93G [00:51<00:21, 68.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  70% 3.46G/4.93G [00:51<00:21, 68.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  70% 3.47G/4.93G [00:52<00:20, 69.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  71% 3.48G/4.93G [00:52<00:20, 71.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  71% 3.49G/4.93G [00:52<00:19, 73.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  71% 3.50G/4.93G [00:54<01:41, 14.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  71% 3.51G/4.93G [00:55<01:59, 11.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  72% 3.53G/4.93G [00:56<01:13, 19.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  72% 3.55G/4.93G [00:56<00:46, 29.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  72% 3.57G/4.93G [00:56<00:40, 33.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  72% 3.58G/4.93G [00:56<00:35, 37.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  73% 3.59G/4.93G [00:56<00:31, 42.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  73% 3.60G/4.93G [00:56<00:27, 47.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  73% 3.61G/4.93G [00:56<00:24, 53.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  73% 3.62G/4.93G [00:57<00:23, 55.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  74% 3.63G/4.93G [00:57<00:22, 59.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  74% 3.64G/4.93G [00:57<00:20, 63.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  74% 3.65G/4.93G [00:57<00:19, 64.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  74% 3.66G/4.93G [00:57<00:19, 65.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  74% 3.67G/4.93G [00:57<00:18, 68.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  75% 3.68G/4.93G [00:57<00:18, 69.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  75% 3.69G/4.93G [00:58<00:17, 70.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  75% 3.70G/4.93G [00:58<00:17, 71.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  75% 3.71G/4.93G [00:58<00:16, 73.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  75% 3.72G/4.93G [00:58<00:16, 75.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  76% 3.73G/4.93G [00:58<00:16, 72.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  76% 3.74G/4.93G [00:58<00:16, 73.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  76% 3.75G/4.93G [00:58<00:16, 72.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  76% 3.76G/4.93G [00:59<00:16, 72.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  77% 3.77G/4.93G [00:59<00:15, 72.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  77% 3.79G/4.93G [00:59<00:15, 73.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  77% 3.80G/4.93G [00:59<00:17, 66.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  77% 3.81G/4.93G [00:59<00:16, 68.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  77% 3.82G/4.93G [00:59<00:15, 71.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  78% 3.83G/4.93G [00:59<00:14, 74.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  78% 3.84G/4.93G [01:00<00:15, 71.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  78% 3.85G/4.93G [01:00<00:14, 72.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  78% 3.86G/4.93G [01:00<00:14, 74.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  78% 3.87G/4.93G [01:00<00:14, 73.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  79% 3.88G/4.93G [01:00<00:13, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  79% 3.89G/4.93G [01:00<00:14, 71.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  79% 3.90G/4.93G [01:01<00:15, 66.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  79% 3.91G/4.93G [01:01<00:15, 65.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  79% 3.92G/4.93G [01:01<00:15, 64.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  80% 3.93G/4.93G [01:01<00:15, 63.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  80% 3.94G/4.93G [01:01<00:14, 66.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  80% 3.95G/4.93G [01:01<00:16, 61.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  80% 3.96G/4.93G [01:02<00:15, 63.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  81% 3.97G/4.93G [01:02<00:15, 60.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  81% 3.98G/4.93G [01:02<00:15, 62.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  81% 4.00G/4.93G [01:02<00:15, 61.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  81% 4.01G/4.93G [01:02<00:13, 66.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  81% 4.02G/4.93G [01:02<00:13, 70.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  82% 4.03G/4.93G [01:02<00:12, 70.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  82% 4.04G/4.93G [01:03<00:12, 72.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  82% 4.05G/4.93G [01:03<00:14, 60.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  82% 4.06G/4.93G [01:03<00:14, 61.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  82% 4.07G/4.93G [01:03<00:15, 57.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  83% 4.08G/4.93G [01:03<00:15, 53.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  83% 4.09G/4.93G [01:04<00:15, 53.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  83% 4.10G/4.93G [01:04<00:14, 58.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  83% 4.11G/4.93G [01:04<00:12, 63.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  84% 4.12G/4.93G [01:04<00:12, 66.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  84% 4.13G/4.93G [01:04<00:11, 70.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  84% 4.14G/4.93G [01:04<00:11, 69.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  84% 4.15G/4.93G [01:04<00:11, 70.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  84% 4.16G/4.93G [01:05<00:10, 72.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  85% 4.17G/4.93G [01:05<00:10, 74.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  85% 4.18G/4.93G [01:05<00:10, 75.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  85% 4.19G/4.93G [01:05<00:10, 73.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  85% 4.20G/4.93G [01:05<00:09, 75.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  85% 4.22G/4.93G [01:05<00:09, 77.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  86% 4.23G/4.93G [01:05<00:09, 73.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  86% 4.24G/4.93G [01:06<00:10, 68.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  86% 4.25G/4.93G [01:06<00:09, 68.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  86% 4.26G/4.93G [01:06<00:10, 67.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  87% 4.27G/4.93G [01:06<00:09, 67.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  87% 4.28G/4.93G [01:06<00:09, 66.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  87% 4.29G/4.93G [01:06<00:09, 68.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  87% 4.30G/4.93G [01:07<00:10, 60.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  87% 4.31G/4.93G [01:07<00:09, 65.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  88% 4.32G/4.93G [01:07<00:12, 48.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  88% 4.34G/4.93G [01:07<00:08, 72.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  88% 4.35G/4.93G [01:07<00:07, 72.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  88% 4.36G/4.93G [01:07<00:07, 73.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  89% 4.37G/4.93G [01:08<00:07, 73.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  89% 4.38G/4.93G [01:08<00:07, 70.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  89% 4.39G/4.93G [01:08<00:07, 71.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  89% 4.40G/4.93G [01:08<00:07, 71.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  89% 4.41G/4.93G [01:08<00:07, 72.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  90% 4.42G/4.93G [01:08<00:07, 69.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  90% 4.44G/4.93G [01:09<00:07, 67.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  90% 4.45G/4.93G [01:09<00:07, 66.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  90% 4.46G/4.93G [01:09<00:06, 69.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  91% 4.47G/4.93G [01:09<00:06, 70.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  91% 4.48G/4.93G [01:09<00:07, 62.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  91% 4.49G/4.93G [01:09<00:06, 66.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  91% 4.50G/4.93G [01:09<00:06, 68.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  91% 4.51G/4.93G [01:10<00:06, 65.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  92% 4.52G/4.93G [01:10<00:06, 65.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  92% 4.53G/4.93G [01:10<00:06, 65.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  92% 4.54G/4.93G [01:10<00:05, 68.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  92% 4.55G/4.93G [01:10<00:05, 65.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  92% 4.56G/4.93G [01:10<00:05, 69.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  93% 4.57G/4.93G [01:11<00:05, 71.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  93% 4.58G/4.93G [01:11<00:04, 72.1MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  93% 4.59G/4.93G [01:11<00:04, 73.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  93% 4.60G/4.93G [01:11<00:04, 72.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  94% 4.61G/4.93G [01:11<00:04, 69.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  94% 4.62G/4.93G [01:11<00:04, 70.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  94% 4.63G/4.93G [01:11<00:04, 68.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  94% 4.65G/4.93G [01:12<00:04, 70.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  94% 4.66G/4.93G [01:12<00:03, 71.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  95% 4.67G/4.93G [01:12<00:03, 73.6MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  95% 4.68G/4.93G [01:12<00:03, 75.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  95% 4.69G/4.93G [01:12<00:03, 75.4MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  95% 4.70G/4.93G [01:12<00:03, 72.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  95% 4.71G/4.93G [01:12<00:03, 74.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  96% 4.72G/4.93G [01:13<00:02, 75.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  96% 4.73G/4.93G [01:13<00:02, 74.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  96% 4.74G/4.93G [01:13<00:02, 75.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  96% 4.75G/4.93G [01:13<00:02, 75.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  96% 4.76G/4.93G [01:14<00:04, 35.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  97% 4.78G/4.93G [01:14<00:02, 55.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  97% 4.79G/4.93G [01:14<00:02, 59.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  97% 4.80G/4.93G [01:14<00:02, 62.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  98% 4.81G/4.93G [01:14<00:01, 65.2MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  98% 4.82G/4.93G [01:14<00:01, 66.0MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  98% 4.83G/4.93G [01:14<00:01, 69.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  98% 4.84G/4.93G [01:15<00:01, 70.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  98% 4.85G/4.93G [01:15<00:01, 72.7MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  99% 4.87G/4.93G [01:15<00:00, 71.3MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  99% 4.88G/4.93G [01:15<00:00, 71.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  99% 4.89G/4.93G [01:15<00:00, 72.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  99% 4.90G/4.93G [01:15<00:00, 72.5MB/s]\u001b[A\n","model-00005-of-00006.safetensors:  99% 4.91G/4.93G [01:15<00:00, 73.8MB/s]\u001b[A\n","model-00005-of-00006.safetensors: 100% 4.92G/4.93G [01:16<00:00, 72.9MB/s]\u001b[A\n","model-00005-of-00006.safetensors: 100% 4.93G/4.93G [01:16<00:00, 64.6MB/s]\n","Downloading shards:  83% 5/6 [08:16<01:36, 96.14s/it] \n","model-00006-of-00006.safetensors:   0% 0.00/2.02G [00:00<?, ?B/s]\u001b[A\n","model-00006-of-00006.safetensors:   1% 10.5M/2.02G [00:01<03:12, 10.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   1% 21.0M/2.02G [00:01<02:05, 16.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   2% 31.5M/2.02G [00:01<01:54, 17.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   2% 41.9M/2.02G [00:02<01:38, 20.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   3% 52.4M/2.02G [00:02<01:29, 22.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   3% 62.9M/2.02G [00:03<01:23, 23.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   4% 73.4M/2.02G [00:03<01:19, 24.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   4% 83.9M/2.02G [00:03<01:17, 25.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   5% 94.4M/2.02G [00:04<01:15, 25.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   5% 105M/2.02G [00:04<01:13, 25.9MB/s] \u001b[A\n","model-00006-of-00006.safetensors:   6% 115M/2.02G [00:05<01:13, 25.9MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   6% 126M/2.02G [00:05<01:11, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   7% 136M/2.02G [00:05<01:11, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   7% 147M/2.02G [00:06<01:10, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   8% 157M/2.02G [00:06<01:10, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   8% 168M/2.02G [00:07<01:11, 25.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   9% 178M/2.02G [00:07<01:08, 26.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:   9% 189M/2.02G [00:07<01:08, 26.9MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  10% 199M/2.02G [00:08<01:08, 26.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  10% 210M/2.02G [00:08<01:09, 26.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  11% 220M/2.02G [00:09<01:08, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  11% 231M/2.02G [00:09<01:07, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  12% 241M/2.02G [00:09<01:08, 25.9MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  12% 252M/2.02G [00:10<01:12, 24.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  13% 262M/2.02G [00:10<01:10, 25.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  13% 273M/2.02G [00:11<01:08, 25.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  14% 283M/2.02G [00:11<01:07, 25.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  15% 294M/2.02G [00:11<01:06, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  15% 304M/2.02G [00:12<01:05, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  16% 315M/2.02G [00:12<01:04, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  16% 325M/2.02G [00:13<01:04, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  17% 336M/2.02G [00:13<01:03, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  17% 346M/2.02G [00:13<01:03, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  18% 357M/2.02G [00:14<01:02, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  18% 367M/2.02G [00:14<01:02, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  19% 377M/2.02G [00:15<01:01, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  19% 388M/2.02G [00:15<01:02, 26.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  20% 398M/2.02G [00:15<01:00, 26.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  20% 409M/2.02G [00:16<01:00, 26.7MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  21% 419M/2.02G [00:16<00:59, 26.7MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  21% 430M/2.02G [00:17<01:00, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  22% 440M/2.02G [00:17<00:59, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  22% 451M/2.02G [00:17<00:59, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  23% 461M/2.02G [00:18<00:59, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  23% 472M/2.02G [00:18<01:00, 25.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  24% 482M/2.02G [00:19<00:59, 25.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  24% 493M/2.02G [00:19<00:58, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  25% 503M/2.02G [00:19<00:58, 25.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  25% 514M/2.02G [00:20<00:58, 26.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  26% 524M/2.02G [00:20<00:58, 25.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  26% 535M/2.02G [00:21<00:57, 25.9MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  27% 545M/2.02G [00:21<00:56, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  27% 556M/2.02G [00:21<00:55, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  28% 566M/2.02G [00:22<00:55, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  29% 577M/2.02G [00:22<00:54, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  29% 587M/2.02G [00:23<00:54, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  30% 598M/2.02G [00:23<00:53, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  30% 608M/2.02G [00:23<00:53, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  31% 619M/2.02G [00:24<00:52, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  31% 629M/2.02G [00:24<00:52, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  32% 640M/2.02G [00:25<00:52, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  32% 650M/2.02G [00:25<00:51, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  33% 661M/2.02G [00:25<00:51, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  33% 671M/2.02G [00:26<00:50, 26.7MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  34% 682M/2.02G [00:26<00:50, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  34% 692M/2.02G [00:27<00:50, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  35% 703M/2.02G [00:27<00:49, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  35% 713M/2.02G [00:27<00:49, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  36% 724M/2.02G [00:28<00:49, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  36% 734M/2.02G [00:28<00:48, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  37% 744M/2.02G [00:29<00:49, 25.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  37% 755M/2.02G [00:29<00:48, 26.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  38% 765M/2.02G [00:29<00:47, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  38% 776M/2.02G [00:30<00:47, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  39% 786M/2.02G [00:30<00:46, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  39% 797M/2.02G [00:31<00:46, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  40% 807M/2.02G [00:31<00:45, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  40% 818M/2.02G [00:31<00:45, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  41% 828M/2.02G [00:32<00:44, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  41% 839M/2.02G [00:32<00:44, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  42% 849M/2.02G [00:33<00:44, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  43% 860M/2.02G [00:33<00:44, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  43% 870M/2.02G [00:33<00:43, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  44% 881M/2.02G [00:34<00:44, 25.8MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  44% 891M/2.02G [00:34<00:43, 26.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  45% 902M/2.02G [00:35<00:42, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  45% 912M/2.02G [00:35<00:42, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  46% 923M/2.02G [00:35<00:42, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  46% 933M/2.02G [00:36<00:41, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  47% 944M/2.02G [00:36<00:40, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  47% 954M/2.02G [00:37<00:40, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  48% 965M/2.02G [00:37<00:40, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  48% 975M/2.02G [00:37<00:39, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  49% 986M/2.02G [00:38<00:39, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  49% 996M/2.02G [00:38<00:38, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  50% 1.01G/2.02G [00:39<00:38, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  50% 1.02G/2.02G [00:39<00:37, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  51% 1.03G/2.02G [00:39<00:37, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  51% 1.04G/2.02G [00:40<00:37, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  52% 1.05G/2.02G [00:40<00:36, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  52% 1.06G/2.02G [00:41<00:37, 25.9MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  53% 1.07G/2.02G [00:41<00:36, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  53% 1.08G/2.02G [00:41<00:36, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  54% 1.09G/2.02G [00:42<00:39, 23.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  54% 1.10G/2.02G [00:42<00:33, 27.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  55% 1.11G/2.02G [00:42<00:33, 27.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  55% 1.12G/2.02G [00:43<00:33, 27.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  56% 1.13G/2.02G [00:43<00:33, 26.7MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  57% 1.14G/2.02G [00:44<00:33, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  57% 1.15G/2.02G [00:44<00:32, 26.7MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  58% 1.16G/2.02G [00:44<00:32, 26.7MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  58% 1.17G/2.02G [00:45<00:31, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  59% 1.18G/2.02G [00:45<00:32, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  59% 1.20G/2.02G [00:46<00:31, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  60% 1.21G/2.02G [00:46<00:30, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  60% 1.22G/2.02G [00:46<00:30, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  61% 1.23G/2.02G [00:47<00:30, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  61% 1.24G/2.02G [00:47<00:29, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  62% 1.25G/2.02G [00:48<00:29, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  62% 1.26G/2.02G [00:48<00:28, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  63% 1.27G/2.02G [00:48<00:28, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  63% 1.28G/2.02G [00:49<00:28, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  64% 1.29G/2.02G [00:49<00:27, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  64% 1.30G/2.02G [00:50<00:27, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  65% 1.31G/2.02G [00:50<00:27, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  65% 1.32G/2.02G [00:50<00:26, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  66% 1.33G/2.02G [00:51<00:26, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  66% 1.34G/2.02G [00:51<00:25, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  67% 1.35G/2.02G [00:52<00:25, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  67% 1.36G/2.02G [00:52<00:24, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  68% 1.37G/2.02G [00:52<00:24, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  68% 1.38G/2.02G [00:53<00:24, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  69% 1.39G/2.02G [00:53<00:23, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  69% 1.41G/2.02G [00:54<00:23, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  70% 1.42G/2.02G [00:54<00:22, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  71% 1.43G/2.02G [00:54<00:22, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  71% 1.44G/2.02G [00:55<00:22, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  72% 1.45G/2.02G [00:55<00:21, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  72% 1.46G/2.02G [00:56<00:21, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  73% 1.47G/2.02G [00:56<00:21, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  73% 1.48G/2.02G [00:56<00:20, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  74% 1.49G/2.02G [00:57<00:20, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  74% 1.50G/2.02G [00:57<00:20, 26.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  75% 1.51G/2.02G [00:58<00:19, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  75% 1.52G/2.02G [00:58<00:19, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  76% 1.53G/2.02G [00:58<00:18, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  76% 1.54G/2.02G [00:59<00:18, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  77% 1.55G/2.02G [00:59<00:17, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  77% 1.56G/2.02G [01:00<00:17, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  78% 1.57G/2.02G [01:00<00:17, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  78% 1.58G/2.02G [01:00<00:16, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  79% 1.59G/2.02G [01:01<00:16, 26.7MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  79% 1.60G/2.02G [01:01<00:15, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  80% 1.61G/2.02G [01:02<00:15, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  80% 1.63G/2.02G [01:02<00:14, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  81% 1.64G/2.02G [01:02<00:14, 26.6MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  81% 1.65G/2.02G [01:03<00:14, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  82% 1.66G/2.02G [01:03<00:13, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  82% 1.67G/2.02G [01:04<00:13, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  83% 1.68G/2.02G [01:04<00:13, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  83% 1.69G/2.02G [01:04<00:12, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  84% 1.70G/2.02G [01:05<00:12, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  85% 1.71G/2.02G [01:05<00:11, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  85% 1.72G/2.02G [01:06<00:11, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  86% 1.73G/2.02G [01:06<00:11, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  86% 1.74G/2.02G [01:06<00:10, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  87% 1.75G/2.02G [01:07<00:10, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  87% 1.76G/2.02G [01:07<00:09, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  88% 1.77G/2.02G [01:08<00:09, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  88% 1.78G/2.02G [01:08<00:09, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  89% 1.79G/2.02G [01:08<00:08, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  89% 1.80G/2.02G [01:09<00:08, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  90% 1.81G/2.02G [01:09<00:07, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  90% 1.82G/2.02G [01:10<00:07, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  91% 1.84G/2.02G [01:10<00:07, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  91% 1.85G/2.02G [01:10<00:06, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  92% 1.86G/2.02G [01:11<00:06, 26.0MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  92% 1.87G/2.02G [01:11<00:05, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  93% 1.88G/2.02G [01:12<00:05, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  93% 1.89G/2.02G [01:12<00:05, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  94% 1.90G/2.02G [01:12<00:04, 26.2MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  94% 1.91G/2.02G [01:13<00:04, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  95% 1.92G/2.02G [01:13<00:03, 26.1MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  95% 1.93G/2.02G [01:14<00:03, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  96% 1.94G/2.02G [01:14<00:03, 26.3MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  96% 1.95G/2.02G [01:14<00:02, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  97% 1.96G/2.02G [01:15<00:02, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  98% 1.97G/2.02G [01:15<00:01, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  98% 1.98G/2.02G [01:16<00:01, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  99% 1.99G/2.02G [01:16<00:01, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors:  99% 2.00G/2.02G [01:16<00:00, 26.5MB/s]\u001b[A\n","model-00006-of-00006.safetensors: 100% 2.01G/2.02G [01:17<00:00, 26.4MB/s]\u001b[A\n","model-00006-of-00006.safetensors: 100% 2.02G/2.02G [01:17<00:00, 26.1MB/s]\n","Downloading shards: 100% 6/6 [09:34<00:00, 95.79s/it]\n","[INFO|modeling_utils.py:1621] 2024-09-22 08:42:52,828 >> Instantiating LlavaForConditionalGeneration model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:1097] 2024-09-22 08:42:52,830 >> Generate config GenerationConfig {\n","  \"pad_token_id\": 32001\n","}\n","\n","[INFO|configuration_utils.py:1097] 2024-09-22 08:42:53,482 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2\n","}\n","\n","Loading checkpoint shards: 100% 6/6 [02:08<00:00, 21.36s/it]\n","[INFO|modeling_utils.py:4544] 2024-09-22 08:45:03,061 >> All model checkpoint weights were used when initializing LlavaForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4552] 2024-09-22 08:45:03,061 >> All the weights of LlavaForConditionalGeneration were initialized from the model checkpoint at llava-hf/llava-1.5-13b-hf.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use LlavaForConditionalGeneration for predictions without further training.\n","generation_config.json: 100% 141/141 [00:00<00:00, 802kB/s]\n","[INFO|configuration_utils.py:1052] 2024-09-22 08:45:03,580 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/generation_config.json\n","[INFO|configuration_utils.py:1097] 2024-09-22 08:45:03,581 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"pad_token_id\": 32001\n","}\n","\n","09/22/2024 08:45:04 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n","09/22/2024 08:45:04 - INFO - llamafactory.model.model_utils.visual - Casting multimodal projector outputs in torch.bfloat16.\n","09/22/2024 08:45:04 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n","09/22/2024 08:45:04 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","09/22/2024 08:45:04 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","09/22/2024 08:45:04 - INFO - llamafactory.model.model_utils.misc - Found linear modules: v_proj,down_proj,k_proj,o_proj,q_proj,up_proj,gate_proj\n","09/22/2024 08:45:04 - INFO - llamafactory.model.loader - trainable params: 31,293,440 || all params: 13,382,788,096 || trainable%: 0.2338\n","[INFO|trainer.py:667] 2024-09-22 08:45:04,895 >> Using auto half precision backend\n","[INFO|trainer.py:2212] 2024-09-22 08:45:05,467 >> ***** Running training *****\n","[INFO|trainer.py:2213] 2024-09-22 08:45:05,467 >>   Num examples = 500\n","[INFO|trainer.py:2214] 2024-09-22 08:45:05,467 >>   Num Epochs = 1\n","[INFO|trainer.py:2215] 2024-09-22 08:45:05,467 >>   Instantaneous batch size per device = 2\n","[INFO|trainer.py:2218] 2024-09-22 08:45:05,467 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:2219] 2024-09-22 08:45:05,467 >>   Gradient Accumulation steps = 8\n","[INFO|trainer.py:2220] 2024-09-22 08:45:05,467 >>   Total optimization steps = 31\n","[INFO|trainer.py:2221] 2024-09-22 08:45:05,475 >>   Number of trainable parameters = 31,293,440\n","  0% 0/31 [00:00<?, ?it/s][WARNING|logging.py:328] 2024-09-22 08:45:06,129 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","[WARNING|logging.py:328] 2024-09-22 08:45:11,206 >> Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"," 16% 5/31 [09:53<51:53, 119.75s/it]09/22/2024 08:54:59 - INFO - llamafactory.train.callbacks - {'loss': 1.2617, 'learning_rate': 4.6859e-05, 'epoch': 0.16, 'throughput': 23.09}\n","{'loss': 1.2617, 'grad_norm': 0.41765284538269043, 'learning_rate': 4.685866540361456e-05, 'epoch': 0.16, 'num_input_tokens_seen': 13712}\n"," 32% 10/31 [19:23<41:13, 117.80s/it]09/22/2024 09:04:28 - INFO - llamafactory.train.callbacks - {'loss': 1.2150, 'learning_rate': 3.8224e-05, 'epoch': 0.32, 'throughput': 23.12}\n","{'loss': 1.215, 'grad_norm': 0.7297236323356628, 'learning_rate': 3.822410025817406e-05, 'epoch': 0.32, 'num_input_tokens_seen': 26896}\n"," 48% 15/31 [29:19<30:21, 113.82s/it]09/22/2024 09:14:24 - INFO - llamafactory.train.callbacks - {'loss': 1.3440, 'learning_rate': 2.6266e-05, 'epoch': 0.48, 'throughput': 23.22}\n","{'loss': 1.344, 'grad_norm': 0.7644486427307129, 'learning_rate': 2.6266229220967818e-05, 'epoch': 0.48, 'num_input_tokens_seen': 40848}\n"," 65% 20/31 [39:01<20:15, 110.53s/it]09/22/2024 09:24:06 - INFO - llamafactory.train.callbacks - {'loss': 1.2541, 'learning_rate': 1.3990e-05, 'epoch': 0.64, 'throughput': 23.23}\n","{'loss': 1.2541, 'grad_norm': 1.5144437551498413, 'learning_rate': 1.399014621105914e-05, 'epoch': 0.64, 'num_input_tokens_seen': 54384}\n"," 81% 25/31 [50:41<13:22, 133.72s/it]09/22/2024 09:35:47 - INFO - llamafactory.train.callbacks - {'loss': 1.2580, 'learning_rate': 4.4809e-06, 'epoch': 0.80, 'throughput': 23.32}\n","{'loss': 1.258, 'grad_norm': 1.0212844610214233, 'learning_rate': 4.480913969818098e-06, 'epoch': 0.8, 'num_input_tokens_seen': 70928}\n"," 97% 30/31 [1:00:12<01:55, 115.10s/it]09/22/2024 09:45:18 - INFO - llamafactory.train.callbacks - {'loss': 1.2804, 'learning_rate': 1.2827e-07, 'epoch': 0.96, 'throughput': 23.25}\n","{'loss': 1.2804, 'grad_norm': 0.8515098094940186, 'learning_rate': 1.2826691520262114e-07, 'epoch': 0.96, 'num_input_tokens_seen': 84016}\n","100% 31/31 [1:01:46<00:00, 108.58s/it][INFO|trainer.py:3674] 2024-09-22 09:46:51,693 >> Saving model checkpoint to saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/checkpoint-31\n","[INFO|configuration_utils.py:672] 2024-09-22 09:46:52,240 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/config.json\n","[INFO|configuration_utils.py:739] 2024-09-22 09:46:52,242 >> Model config LlavaConfig {\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_seq_length\": 576,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"meta-llama/Llama-2-13b-hf\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"attention_bias\": false,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": 1,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 2,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"head_dim\": 128,\n","    \"hidden_act\": \"silu\",\n","    \"hidden_size\": 5120,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 13824,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 4096,\n","    \"min_length\": 0,\n","    \"mlp_bias\": false,\n","    \"model_type\": \"llama\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 40,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 40,\n","    \"num_key_value_heads\": 40,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"prefix\": null,\n","    \"pretraining_tp\": 1,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"rms_norm_eps\": 1e-05,\n","    \"rope_scaling\": null,\n","    \"rope_theta\": 10000.0,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": false,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": \"float16\",\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.45.0.dev0\",\n","  \"vision_config\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": null,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"quick_gelu\",\n","    \"hidden_size\": 1024,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"image_size\": 336,\n","    \"initializer_factor\": 1.0,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 4096,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-05,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"min_length\": 0,\n","    \"model_type\": \"clip_vision_model\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 16,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 24,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"patch_size\": 14,\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"projection_dim\": 768,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\",\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|tokenization_utils_base.py:2650] 2024-09-22 09:46:53,002 >> tokenizer config file saved in saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/checkpoint-31/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2659] 2024-09-22 09:46:53,003 >> Special tokens file saved in saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/checkpoint-31/special_tokens_map.json\n","[INFO|image_processing_base.py:258] 2024-09-22 09:46:57,466 >> Image processor saved in saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/checkpoint-31/preprocessor_config.json\n","[INFO|trainer.py:2474] 2024-09-22 09:46:57,466 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 3711.9915, 'train_samples_per_second': 0.135, 'train_steps_per_second': 0.008, 'train_loss': 1.263348763988864, 'epoch': 0.99, 'num_input_tokens_seen': 86176}\n","100% 31/31 [1:01:51<00:00, 119.74s/it]\n","[INFO|image_processing_base.py:258] 2024-09-22 09:46:57,468 >> Image processor saved in saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/preprocessor_config.json\n","[INFO|trainer.py:3674] 2024-09-22 09:46:57,469 >> Saving model checkpoint to saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40\n","[INFO|configuration_utils.py:672] 2024-09-22 09:46:57,990 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/config.json\n","[INFO|configuration_utils.py:739] 2024-09-22 09:46:57,991 >> Model config LlavaConfig {\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_seq_length\": 576,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"meta-llama/Llama-2-13b-hf\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"attention_bias\": false,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": 1,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 2,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"head_dim\": 128,\n","    \"hidden_act\": \"silu\",\n","    \"hidden_size\": 5120,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 13824,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 4096,\n","    \"min_length\": 0,\n","    \"mlp_bias\": false,\n","    \"model_type\": \"llama\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 40,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 40,\n","    \"num_key_value_heads\": 40,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"prefix\": null,\n","    \"pretraining_tp\": 1,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"rms_norm_eps\": 1e-05,\n","    \"rope_scaling\": null,\n","    \"rope_theta\": 10000.0,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": false,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": \"float16\",\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.45.0.dev0\",\n","  \"vision_config\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": null,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"quick_gelu\",\n","    \"hidden_size\": 1024,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"image_size\": 336,\n","    \"initializer_factor\": 1.0,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 4096,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-05,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"min_length\": 0,\n","    \"model_type\": \"clip_vision_model\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 16,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 24,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"patch_size\": 14,\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"projection_dim\": 768,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\",\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|tokenization_utils_base.py:2650] 2024-09-22 09:46:58,459 >> tokenizer config file saved in saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2659] 2024-09-22 09:46:58,459 >> Special tokens file saved in saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =      0.992\n","  num_input_tokens_seen    =      86176\n","  total_flos               =  6365088GF\n","  train_loss               =     1.2633\n","  train_runtime            = 1:01:51.99\n","  train_samples_per_second =      0.135\n","  train_steps_per_second   =      0.008\n","Figure saved at: saves/LLaVA1.5-13B-Chat/lora/train_2024-09-22-08-31-40/training_loss.png\n","09/22/2024 09:46:58 - WARNING - llamafactory.extras.ploting - No metric eval_loss to plot.\n","09/22/2024 09:46:58 - WARNING - llamafactory.extras.ploting - No metric eval_accuracy to plot.\n","[INFO|modelcard.py:449] 2024-09-22 09:46:58,744 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n","[INFO|configuration_utils.py:672] 2024-09-22 09:48:33,607 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/config.json\n","[INFO|configuration_utils.py:739] 2024-09-22 09:48:33,618 >> Model config LlavaConfig {\n","  \"_name_or_path\": \"llava-hf/llava-1.5-13b-hf\",\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_seq_length\": 576,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"meta-llama/Llama-2-13b-hf\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"attention_bias\": false,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": 1,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 2,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"head_dim\": 128,\n","    \"hidden_act\": \"silu\",\n","    \"hidden_size\": 5120,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 13824,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 4096,\n","    \"min_length\": 0,\n","    \"mlp_bias\": false,\n","    \"model_type\": \"llama\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 40,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 40,\n","    \"num_key_value_heads\": 40,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"prefix\": null,\n","    \"pretraining_tp\": 1,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"rms_norm_eps\": 1e-05,\n","    \"rope_scaling\": null,\n","    \"rope_theta\": 10000.0,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": false,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": \"float16\",\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.45.0.dev0\",\n","  \"vision_config\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": null,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"quick_gelu\",\n","    \"hidden_size\": 1024,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"image_size\": 336,\n","    \"initializer_factor\": 1.0,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 4096,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-05,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"min_length\": 0,\n","    \"model_type\": \"clip_vision_model\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 16,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 24,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"patch_size\": 14,\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"projection_dim\": 768,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\",\n","  \"vocab_size\": 32064\n","}\n","\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:33,844 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.model\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:33,844 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:33,844 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/added_tokens.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:33,844 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:33,844 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2479] 2024-09-22 09:48:33,915 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[INFO|image_processing_base.py:375] 2024-09-22 09:48:34,582 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/preprocessor_config.json\n","[INFO|image_processing_base.py:375] 2024-09-22 09:48:34,802 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/preprocessor_config.json\n","[INFO|image_processing_base.py:429] 2024-09-22 09:48:34,803 >> Image processor CLIPImageProcessor {\n","  \"crop_size\": {\n","    \"height\": 336,\n","    \"width\": 336\n","  },\n","  \"do_center_crop\": true,\n","  \"do_convert_rgb\": true,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.48145466,\n","    0.4578275,\n","    0.40821073\n","  ],\n","  \"image_processor_type\": \"CLIPImageProcessor\",\n","  \"image_std\": [\n","    0.26862954,\n","    0.26130258,\n","    0.27577711\n","  ],\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 336\n","  }\n","}\n","\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:35,020 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.model\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:35,020 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:35,020 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/added_tokens.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:35,020 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2215] 2024-09-22 09:48:35,020 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2479] 2024-09-22 09:48:35,078 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[INFO|processing_utils.py:744] 2024-09-22 09:48:35,610 >> Processor LlavaProcessor:\n","- image_processor: CLIPImageProcessor {\n","  \"crop_size\": {\n","    \"height\": 336,\n","    \"width\": 336\n","  },\n","  \"do_center_crop\": true,\n","  \"do_convert_rgb\": true,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.48145466,\n","    0.4578275,\n","    0.40821073\n","  ],\n","  \"image_processor_type\": \"CLIPImageProcessor\",\n","  \"image_std\": [\n","    0.26862954,\n","    0.26130258,\n","    0.27577711\n","  ],\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 336\n","  }\n","}\n","\n","- tokenizer: LlamaTokenizerFast(name_or_path='llava-hf/llava-1.5-13b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n","\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32000: AddedToken(\"<image>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32001: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n","\n","{\n","  \"image_token\": \"<image>\",\n","  \"patch_size\": null,\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"vision_feature_select_strategy\": null\n","}\n","\n","[INFO|configuration_utils.py:672] 2024-09-22 09:48:35,837 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/config.json\n","[INFO|configuration_utils.py:739] 2024-09-22 09:48:35,840 >> Model config LlavaConfig {\n","  \"_name_or_path\": \"llava-hf/llava-1.5-13b-hf\",\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_seq_length\": 576,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"meta-llama/Llama-2-13b-hf\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"attention_bias\": false,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": 1,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 2,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"head_dim\": 128,\n","    \"hidden_act\": \"silu\",\n","    \"hidden_size\": 5120,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 13824,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 4096,\n","    \"min_length\": 0,\n","    \"mlp_bias\": false,\n","    \"model_type\": \"llama\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 40,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 40,\n","    \"num_key_value_heads\": 40,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"prefix\": null,\n","    \"pretraining_tp\": 1,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"rms_norm_eps\": 1e-05,\n","    \"rope_scaling\": null,\n","    \"rope_theta\": 10000.0,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": false,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": \"float16\",\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.45.0.dev0\",\n","  \"vision_config\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": null,\n","    \"attention_dropout\": 0.0,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"quick_gelu\",\n","    \"hidden_size\": 1024,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"image_size\": 336,\n","    \"initializer_factor\": 1.0,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 4096,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-05,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"min_length\": 0,\n","    \"model_type\": \"clip_vision_model\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 16,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 24,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": null,\n","    \"patch_size\": 14,\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"projection_dim\": 768,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\",\n","  \"vocab_size\": 32064\n","}\n","\n","09/22/2024 09:48:35 - INFO - llamafactory.model.model_utils.quantization - Quantizing model to 4 bit with bitsandbytes.\n","09/22/2024 09:48:35 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n","[INFO|modeling_utils.py:3702] 2024-09-22 09:48:35,869 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/model.safetensors.index.json\n","[INFO|modeling_utils.py:1621] 2024-09-22 09:48:35,872 >> Instantiating LlavaForConditionalGeneration model under default dtype torch.float16.\n","[INFO|configuration_utils.py:1097] 2024-09-22 09:48:35,875 >> Generate config GenerationConfig {\n","  \"pad_token_id\": 32001\n","}\n","\n","[INFO|configuration_utils.py:1097] 2024-09-22 09:48:36,216 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2\n","}\n","\n","Loading checkpoint shards: 100% 6/6 [02:00<00:00, 20.01s/it]\n","[INFO|modeling_utils.py:4544] 2024-09-22 09:50:37,067 >> All model checkpoint weights were used when initializing LlavaForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4552] 2024-09-22 09:50:37,067 >> All the weights of LlavaForConditionalGeneration were initialized from the model checkpoint at llava-hf/llava-1.5-13b-hf.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use LlavaForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1052] 2024-09-22 09:50:37,297 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-13b-hf/snapshots/0fad4a3be201ea4a735c381d4595150a8538d3b4/generation_config.json\n","[INFO|configuration_utils.py:1097] 2024-09-22 09:50:37,298 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"pad_token_id\": 32001\n","}\n","\n","09/22/2024 09:50:37 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n","09/22/2024 09:50:37 - INFO - llamafactory.model.loader - all params: 13,351,494,656\n","09/22/2024 09:50:37 - WARNING - llamafactory.chat.hf_engine - There is no current event loop, creating a new one.\n","[WARNING|logging.py:328] 2024-09-22 10:28:03,334 >> Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"]}],"source":["%cd /content/LLaMA-Factory/\n","!GRADIO_SHARE=1 llamafactory-cli webui"]},{"cell_type":"markdown","metadata":{"id":"rgR3UFhB0Ifq"},"source":["## Fine-tune model via Command Line\n","\n","It takes ~30min for training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CS0Qk5OR0i4Q"},"outputs":[],"source":["import json\n","\n","args = dict(\n","  stage=\"sft\",                        # do supervised fine-tuning\n","  do_train=True,\n","  model_name_or_path=\"unsloth/llama-3-8b-Instruct-bnb-4bit\", # use bnb-4bit-quantized Llama-3-8B-Instruct model\n","  dataset=\"identity,alpaca_en_demo\",             # use alpaca and identity datasets\n","  template=\"llama3\",                     # use llama3 prompt template\n","  finetuning_type=\"lora\",                   # use LoRA adapters to save memory\n","  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n","  output_dir=\"llama3_lora\",                  # the path to save LoRA adapters\n","  per_device_train_batch_size=2,               # the batch size\n","  gradient_accumulation_steps=4,               # the gradient accumulation steps\n","  lr_scheduler_type=\"cosine\",                 # use cosine learning rate scheduler\n","  logging_steps=10,                      # log every 10 steps\n","  warmup_ratio=0.1,                      # use warmup scheduler\n","  save_steps=1000,                      # save checkpoint every 1000 steps\n","  learning_rate=5e-5,                     # the learning rate\n","  num_train_epochs=3.0,                    # the epochs of training\n","  max_samples=500,                      # use 500 examples in each dataset\n","  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n","  loraplus_lr_ratio=16.0,                   # use LoRA+ algorithm with lambda=16.0\n","  fp16=True,                         # use float16 mixed precision training\n","  use_liger_kernel=True,                   # use liger kernel for efficient training\n",")\n","\n","json.dump(args, open(\"train_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n","\n","%cd /content/LLaMA-Factory/\n","\n","!llamafactory-cli train train_llama3.json"]},{"cell_type":"markdown","metadata":{"id":"PVNaC-xS5N40"},"source":["## Infer the fine-tuned model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oh8H9A_25SF9"},"outputs":[],"source":["from llamafactory.chat import ChatModel\n","from llamafactory.extras.misc import torch_gc\n","\n","%cd /content/LLaMA-Factory/\n","\n","args = dict(\n","  model_name_or_path=\"unsloth/llama-3-8b-Instruct-bnb-4bit\", # use bnb-4bit-quantized Llama-3-8B-Instruct model\n","  adapter_name_or_path=\"llama3_lora\",            # load the saved LoRA adapters\n","  template=\"llama3\",                     # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  quantization_bit=4,                    # load 4-bit quantized model\n",")\n","chat_model = ChatModel(args)\n","\n","messages = []\n","print(\"Welcome to the CLI application, use `clear` to remove the history, use `exit` to exit the application.\")\n","while True:\n","  query = input(\"\\nUser: \")\n","  if query.strip() == \"exit\":\n","    break\n","  if query.strip() == \"clear\":\n","    messages = []\n","    torch_gc()\n","    print(\"History has been removed.\")\n","    continue\n","\n","  messages.append({\"role\": \"user\", \"content\": query})\n","  print(\"Assistant: \", end=\"\", flush=True)\n","\n","  response = \"\"\n","  for new_text in chat_model.stream_chat(messages):\n","    print(new_text, end=\"\", flush=True)\n","    response += new_text\n","  print()\n","  messages.append({\"role\": \"assistant\", \"content\": response})\n","\n","torch_gc()"]},{"cell_type":"markdown","metadata":{"id":"kTESHaFvbNTr"},"source":["## Merge the LoRA adapter and optionally upload model\n","\n","NOTE: the Colab free version has merely 12GB RAM, where merging LoRA of a 8B model needs at least 18GB RAM, thus you **cannot** perform it in the free version."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcNcHcA4bf4Z"},"outputs":[],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IMojogHbaOZF"},"outputs":[],"source":["import json\n","\n","args = dict(\n","  model_name_or_path=\"meta-llama/Meta-Llama-3-8B-Instruct\", # use official non-quantized Llama-3-8B-Instruct model\n","  adapter_name_or_path=\"llama3_lora\",            # load the saved LoRA adapters\n","  template=\"llama3\",                     # same to the one in training\n","  finetuning_type=\"lora\",                  # same to the one in training\n","  export_dir=\"llama3_lora_merged\",              # the path to save the merged model\n","  export_size=2,                       # the file shard size (in GB) of the merged model\n","  export_device=\"cpu\",                    # the device used in export, can be chosen from `cpu` and `cuda`\n","  #export_hub_model_id=\"your_id/your_model\",         # the Hugging Face hub ID to upload model\n",")\n","\n","json.dump(args, open(\"merge_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n","\n","%cd /content/LLaMA-Factory/\n","\n","!llamafactory-cli export merge_llama3.json"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9","timestamp":1726553963410}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}